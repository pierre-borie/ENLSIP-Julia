{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook ENLSIP-JULIA-0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra, Polynomials, Printf, JuMP, Ipopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizes the useful informations about an iteration of the algorithm\n",
    "\n",
    "mutable struct Iteration\n",
    "    x::Vector\n",
    "    p::Vector\n",
    "    rx::Vector\n",
    "    cx::Vector\n",
    "    t::Int64\n",
    "    α::Float64\n",
    "    λ::Vector\n",
    "    w::Vector\n",
    "    rankA::Int64\n",
    "    rankJ2::Int64\n",
    "    dimA::Int64\n",
    "    dimJ2::Int64\n",
    "    b_gn::Vector\n",
    "    d_gn::Vector\n",
    "    predicted_reduction::Float64\n",
    "    progress::Float64\n",
    "    β::Float64\n",
    "    restart::Bool\n",
    "    first::Bool\n",
    "    add::Bool\n",
    "    del::Bool\n",
    "    index_del::Int64\n",
    "    code::Int64\n",
    "end\n",
    "\n",
    "Base.copy(s::Iteration) = Iteration(s.x, s.p, s.rx, s.cx, s.t, s.α, s.λ, s.w, s.rankA, s.rankJ2, s.dimA, s.dimJ2, s.b_gn, s.d_gn, s.predicted_reduction, s.progress, s.β, s.restart, s.first, s.add, s.del, s.index_del, s.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reprensents the useful informations about constraints at a point x, i.e. :\n",
    "# cx : constraint function evaluation\n",
    "# A : constraint jacobian evaluation\n",
    "\n",
    "# Used to distinguish active constraints\n",
    "\n",
    "mutable struct Constraint\n",
    "    cx::Vector\n",
    "    A::Matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In ENLSIP, the working-set is a prediction of the set of active constraints at the solution\n",
    "# It is updated at every iteration thanks to a Lagrangian multipliers estimation\n",
    "\n",
    "# The fields summarize infos about the qualification of the constraints, i.e. :\n",
    "# q : number of equality constraints\n",
    "# t : number of constraints considered to be active (all equalities and some inequalities)\n",
    "# l : total number of constraints (equality and inequality)\n",
    "# active : indeces of the constraints considered as active (total length : l)\n",
    "# inactive : indeces of the inequality constraints considered inactive (total length : l-t)\n",
    "\n",
    "\n",
    "mutable struct WorkingSet\n",
    "    q::Int64\n",
    "    t::Int64\n",
    "    l::Int64\n",
    "    active::Vector{Int64}\n",
    "    inactive::Vector{Int64}\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENLSIP functions\n",
    "\n",
    "Capital names before definitions represent Fortran77 equivalent routines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pseudo_rank (generic function with 2 methods)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computes and returns the rank of a triangular matrix T using its diagonal elements placed in decreasing order\n",
    "# according to their absolute value\n",
    "\n",
    "# diag_T is the diagonal of the Triangular matrix T whose rank is estimated\n",
    "# τ is the relative tolerance to estimate the rank\n",
    "\n",
    "function pseudo_rank(diag_T::Vector, τ::Float64 = sqrt(eps(Float64)))\n",
    "    if isempty(diag_T) || abs(diag_T[1]) < τ\n",
    "        r = 0\n",
    "    else\n",
    "        r = 1\n",
    "        for j in eachindex(diag_T)\n",
    "            if max(abs(diag_T[j] / diag_T[1]), abs(diag_T[j])) >= τ\n",
    "                r = j\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return r\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Struct used to define functions evaluating residuals, constraints and corresponding jacobians\n",
    "# Both functions for residuals and constraints must be written as follows :\n",
    "# (h::EvalFunc)(x::Vector,hx::Vector,Jh::Matrix)\n",
    "\n",
    "# ctrl field control what is computed i.e. function evalutation or jacobian\n",
    "# ctrl = 1 means evaluate the function at point x, (modifies vector hx)\n",
    "# ctrl = 2 means calculate the jacobian of h(x) at point x if jacobian is supplied anatically\n",
    "#        (modifies matrix Jh)\n",
    "#        if not, ctrl is set to 0 on return and jacobian is computed numerically.\n",
    "\n",
    "abstract type EvalFunc end\n",
    "\n",
    "mutable struct ResidualsEval <: EvalFunc\n",
    "    ctrl::Int64\n",
    "end\n",
    "\n",
    "mutable struct ConstraintsEval <: EvalFunc\n",
    "    ctrl::Int64\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jac_forward_diff! (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JACDIF\n",
    "# Compute the (m x n) jacobian of h(x) at the current point by using forward differences\n",
    "# Result is stored in place in the matrix Jh\n",
    "function jac_forward_diff!(\n",
    "    x::Vector,\n",
    "    h::EvalFunc,\n",
    "    hx::Vector,\n",
    "    n::Int64,\n",
    "    m::Int64,\n",
    "    Jh::Matrix)\n",
    "\n",
    "    δ = sqrt(eps(Float64))\n",
    "\n",
    "    for j = 1:n\n",
    "        δ_j = max(abs(x[j]),1.0) * δ\n",
    "        e_j = [(i == j ? 1.0 : 0.0) for i =1:n]\n",
    "        hx_forward = zeros(m)\n",
    "        h.ctrl = 1\n",
    "        x_forward = x + δ_j * e_j\n",
    "        h(x_forward, hx_forward, Jh)\n",
    "\n",
    "        if h.ctrl >= -10\n",
    "            Jh[:,j] = (hx_forward - hx) / δ_j\n",
    "        end\n",
    "    end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_point! (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NEWPNT\n",
    "# Compute in place the jacobians J and A corresponding to the ResidualsEvals and the constraints respectively at current point x\n",
    "\n",
    "function new_point!(x::Vector,\n",
    "                    r::ResidualsEval,\n",
    "                    rx::Vector,\n",
    "                    c::ConstraintsEval,\n",
    "                    cx::Vector,\n",
    "                    J::Matrix,\n",
    "                    A::Matrix,\n",
    "                    n::Int64,\n",
    "                    m::Int64,\n",
    "                    l::Int64)\n",
    "    r.ctrl = 2\n",
    "    r(x,rx,J)\n",
    "    if r.ctrl == 0\n",
    "        # Compute the jacobian numerically\n",
    "        jac_forward_diff!(x,r,rx,n,m,J)\n",
    "    end\n",
    "\n",
    "    c.ctrl = 2\n",
    "    if l != 0\n",
    "        c(x,cx,A)\n",
    "        if c.ctrl == 0\n",
    "            # Compute the jacobian numerically\n",
    "            jac_forward_diff!(x,c,cx,n,l,A)\n",
    "        end\n",
    "    end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sub_search_direction (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SUBDIR\n",
    "# Computes a search direction with Gauss-Newton method using dimA and dimJ2 as subspaces dimensions\n",
    "\n",
    "function sub_search_direction(\n",
    "        J1::Matrix,\n",
    "        J2::Matrix,\n",
    "        rx::Vector,\n",
    "        cx::Vector,\n",
    "        Q1,\n",
    "        P1::Matrix,\n",
    "        L11::Matrix,\n",
    "        Q2,\n",
    "        P2::Matrix,\n",
    "        R11::Matrix,\n",
    "        Q3,\n",
    "        R22::Matrix,\n",
    "        P3::Matrix,\n",
    "        n::Int64,\n",
    "        t::Int64,\n",
    "        rankA::Int64,\n",
    "        dimA::Int64,\n",
    "        dimJ2::Int64,\n",
    "        code::Int64)\n",
    "\n",
    "    # Solving without stabilization\n",
    "    if code == 1\n",
    "        b = -transpose(P1) * cx\n",
    "        δp1 = LowerTriangular(L11) \\ b\n",
    "        p1 = δp1\n",
    "        d = - transpose(Q3) * (J1*p1 + rx)\n",
    "        δp2 = UpperTriangular(R22[1:dimJ2,1:dimJ2]) \\ d[1:dimJ2]\n",
    "        p2 = P3 * [δp2; zeros(n-t-dimJ2)]\n",
    "\n",
    "    # Solving with stabilization\n",
    "    elseif code == -1\n",
    "        b = - transpose(Q2) * transpose(P1) * cx\n",
    "        δp1 = UpperTriangular(R11[1:dimA,1:dimA]) \\ b[1:dimA]\n",
    "        p1 = P2[1:rankA,1:rankA] * [δp1; zeros(rankA-dimA)]\n",
    "        d = - transpose(Q3) * (J1*p1 + rx)\n",
    "        δp2 = UpperTriangular(R22[1:dimJ2, 1:dimJ2]) \\ d[1:dimJ2]\n",
    "        p2 = P3 * [δp2; zeros(n-rankA-dimJ2)]\n",
    "    end\n",
    "\n",
    "    p = Q1 * [p1;p2]\n",
    "    return p, b, d\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gn_search_direction (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GNSRCH\n",
    "# Compute the search direction with the method of Gauss-Newton\n",
    "# dimA and dimJ2 are equal to the rank of the correspondign matrices\n",
    "\n",
    "function gn_search_direction(\n",
    "    A::Matrix,\n",
    "    J::Matrix,\n",
    "    rx::Vector,\n",
    "    cx::Vector,\n",
    "    Q1,\n",
    "    P1::Matrix,\n",
    "    L11::Matrix,\n",
    "    Q2,\n",
    "    P2::Matrix,\n",
    "    R11::Matrix,\n",
    "    rankA::Int64,\n",
    "    t::Int64,\n",
    "    τ::Float64,\n",
    "    current_iter::Iteration)\n",
    "    code = (rankA == t ? 1 : -1)\n",
    "\n",
    "    (m,n) = size(J)\n",
    "    JQ1 = J*Q1\n",
    "    J1, J2 = JQ1[:,1:rankA], JQ1[:,rankA+1:end]\n",
    "    F_J2 = qr(J2, Val(true))\n",
    "    Q3, P3, R22 = F_J2.Q, F_J2.P, F_J2.R\n",
    "    rankJ2 = pseudo_rank(diag(R22), τ)\n",
    "    p_gn, b_gn, d_gn = sub_search_direction(J1, J2,rx,cx,Q1,P1,L11,Q2,P2,R11,Q3,R22,P3,n,t,rankA,rankA,rankJ2,code)\n",
    "    current_iter.rankA = rankA\n",
    "    current_iter.rankJ2 = rankJ2\n",
    "    current_iter.dimA = rankA\n",
    "    current_iter.dimJ2 = rankJ2\n",
    "    current_iter.b_gn = b_gn\n",
    "    current_iter.d_gn = d_gn\n",
    "    return p_gn\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hessian_cons! (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HESSF\n",
    "#                                     m\n",
    "# Compute in place the (n x n) matrix B = Σ  [r_k(x) * G_k]\n",
    "#                                    k=1\n",
    "# where G_k is the hessian of residual r_k(x)\n",
    "\n",
    "function hessian_res!(\n",
    "    r::ResidualsEval,\n",
    "    x::Vector,\n",
    "    rx::Vector,\n",
    "    n::Int64,\n",
    "    m::Int64,\n",
    "    B::Matrix)\n",
    "\n",
    "    # Only residuals evaluation\n",
    "    r.ctrl = 1\n",
    "    dummy = zeros(1,1)\n",
    "    # Data\n",
    "    ε1 = eps(Float64) ^(1/3)\n",
    "\n",
    "    for k = 1:n, j = 1:k\n",
    "        ε_k = max(abs(x[k]),1.0) * ε1\n",
    "        ε_j = max(abs(x[j]),1.0) * ε1\n",
    "        e_k = [i == k for i = 1:n]\n",
    "        e_j = [i == j for i = 1:n]\n",
    "\n",
    "        f1,f2,f3,f4 = zeros(m), zeros(m), zeros(m), zeros(m)\n",
    "        r(x + ε_j*e_j + ε_k*e_k, f1, dummy)\n",
    "        r(x - ε_j*e_j + ε_k*e_k, f2, dummy)\n",
    "        r(x + ε_j*e_j - ε_k*e_k, f3, dummy)\n",
    "        r(x - ε_j*e_j - ε_k*e_k, f4, dummy)\n",
    "\n",
    "        # Compute line j of g_k\n",
    "        g_kj = (f1 - f2 - f3 + f4) / (4 * ε_j * ε_k)\n",
    "\n",
    "        s = dot(g_kj,rx)\n",
    "        B[k,j] = s\n",
    "        if j != k B[j,k] = s end\n",
    "    end\n",
    "end\n",
    "\n",
    "# HESSH\n",
    "#                                         t\n",
    "# Compute in place the (n x n) matrix B = Σ  [λ_i * G_k]\n",
    "#                                        k=1\n",
    "# where G_k is the hessian of residual c_k(x), k in current working set\n",
    "# λ = (λ_1,...,λ_t) are the lagrange multipliers estimates\n",
    "\n",
    "function hessian_cons!(\n",
    "    c::ConstraintsEval,\n",
    "    x::Vector,\n",
    "    λ::Vector,\n",
    "    active::Vector,\n",
    "    n::Int64,\n",
    "    l::Int64,\n",
    "    t::Int64,\n",
    "    B::Matrix)\n",
    "\n",
    "    # Only constraints evaluation\n",
    "    c.ctrl = 1\n",
    "    dummy = zeros(1,1)\n",
    "    # Data\n",
    "    ε1 = eps(Float64) ^(1/3)\n",
    "    active_indeces = @view active[1:t]\n",
    "\n",
    "    for k = 1:n, j = 1:k\n",
    "        ε_k = max(abs(x[k]),1.0) * ε1\n",
    "        ε_j = max(abs(x[j]),1.0) * ε1\n",
    "        e_k = [i == k for i = 1:n]\n",
    "        e_j = [i == j for i = 1:n]\n",
    "\n",
    "        f1,f2,f3,f4 = zeros(l), zeros(l), zeros(l), zeros(l)\n",
    "        c(x + ε_j*e_j + ε_k*e_k, f1, dummy)\n",
    "        c(x - ε_j*e_j + ε_k*e_k, f2, dummy)\n",
    "        c(x + ε_j*e_j - ε_k*e_k, f3, dummy)\n",
    "        c(x - ε_j*e_j - ε_k*e_k, f4, dummy)\n",
    "        act_f1 = @view f1[active_indeces]\n",
    "        act_f2 = @view f2[active_indeces]\n",
    "        act_f3 = @view f3[active_indeces]\n",
    "        act_f4 = @view f4[active_indeces]\n",
    "\n",
    "        # Compute line j of G_k\n",
    "        g_kj = (act_f1 - act_f2 - act_f3 + act_f4) / (4.0 * ε_k * ε_j)\n",
    "        s = dot(g_kj,λ)\n",
    "        B[k,j] = s\n",
    "        if k != j B[j,k] = s end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newton_search_direction (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NEWTON\n",
    "# Computes the search direction p by minimizing :\n",
    "#      T    T                             T       T\n",
    "# 0.5*p * (J * J - c_mat + r_mat) * p + (J * r(x)) * p\n",
    "# s.t.\n",
    "#     A*p + c(x) = 0\n",
    "#\n",
    "#\n",
    "#         t\n",
    "# c_mat = Σ  [λ_i * K_i]\n",
    "#        i=1\n",
    "# where K_i is the hessian of constraint c_i(x), i in current working set\n",
    "#         m\n",
    "# r_mat = Σ  [r_i(x) * G_i]\n",
    "#        i=1\n",
    "# where G_i is the hessian of residual r_i(x)\n",
    "\n",
    "function newton_search_direction(\n",
    "    x::Vector,\n",
    "    c::ConstraintsEval,\n",
    "    r::ResidualsEval,\n",
    "    active_cx::Vector,\n",
    "    active::Vector,\n",
    "    n::Int64,\n",
    "    m::Int64,\n",
    "    l::Int64,\n",
    "    t::Int64,\n",
    "    λ::Vector,\n",
    "    rx::Vector,\n",
    "    J::Matrix,\n",
    "    Q1,\n",
    "    P1::Matrix,\n",
    "    L11::Matrix,\n",
    "    Q2,\n",
    "    R11::Matrix,\n",
    "    P2::Matrix,\n",
    "    rankA::Int64)\n",
    "\n",
    "    if t == rankA\n",
    "        b = -transpose(P1) * active_cx\n",
    "        p1 = LowerTriangular(L11) \\ b\n",
    "     elseif t > rankA\n",
    "        b = -transpose(Q2) * transpose(P1) * active_cx\n",
    "        δp1 = UpperTriangular(R11) \\ b\n",
    "        p1 = P2 * δp1\n",
    "    end\n",
    "\n",
    "    if rankA == n return p1 end\n",
    "\n",
    "    # Computation of J1, J2\n",
    "    JQ1 = J*Q1\n",
    "    J1, J2 = JQ1[:,1:t], JQ1[:,t+1:end]\n",
    "\n",
    "    # Computation of hessian matrices\n",
    "    r_mat, c_mat = zeros(n,n), zeros(n,n)\n",
    "\n",
    "    hessian_res!(r,x,rx,n,m,r_mat)\n",
    "    hessian_cons!(c,x,λ,active,n,l,t,c_mat)\n",
    "\n",
    "    Γ_mat = r_mat - c_mat\n",
    "\n",
    "    if rankA == t\n",
    "        E = transpose(Q1) * Γ_mat * Q1\n",
    "    elseif t > rankA\n",
    "        println(\"n-t = $(n-t)\")\n",
    "        E = transpose([P2;zeros(n-t,t)]) * transpose(Q1) * Γ_mat * Q1 * [P2;zeros(n-t,t)]\n",
    "    end\n",
    "\n",
    "\n",
    "    # Forms the system to compute p2\n",
    "    E21 = E[t+1:n, 1:t]\n",
    "    E22 = E[t+1:n, t+1:n]\n",
    "\n",
    "    W22 = E22 + transpose(J2)*J2\n",
    "    W21 = E21 + transpose(J2)*J1\n",
    "\n",
    "    d = -W21 * p1 - transpose(J2) * rx\n",
    "\n",
    "    if isposdef(W22)\n",
    "        chol_W22 = cholesky(Symmetric(W22))\n",
    "        y = chol_W22.L \\ d\n",
    "        p2 = chol_W22.U \\ y\n",
    "        p = Q1 * [p1;p2]\n",
    "    else\n",
    "        p = zeros(n)\n",
    "    end\n",
    "    return p\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_lagrange_mult_estimate! (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MULEST\n",
    "# Compute first order estimate of Lagrange multipliers\n",
    "\n",
    "function first_lagrange_mult_estimate!(A::Matrix, λ::Vector, ∇fx::Vector, cx::Vector)\n",
    "    # Solves the system A^T * λ_ls = ∇f(x) using qr factorisation of A^T\n",
    "    # A^T*P1 = Q1 * (R)\n",
    "    #              (0)\n",
    "    # with R^T = L11\n",
    "    # then computes estimates of lagrage multipliers by forming :\n",
    "    #                  -1\n",
    "    # λ = λ_ls - (A*A^T) *cx\n",
    "\n",
    "    (t, n) = size(A)\n",
    "    v = zeros(t)\n",
    "    vnz = zeros(t)\n",
    "    F = qr(transpose(A), Val(true))\n",
    "    prankA = pseudo_rank(diag(F.R))\n",
    "    b = transpose(F.Q) * ∇fx\n",
    "    v[1:prankA] = UpperTriangular(F.R[1:prankA,1:prankA]) \\ b[1:prankA]\n",
    "    if prankA < t\n",
    "        v[prankA+1:t] = zeros(t - prankA)\n",
    "    end\n",
    "    λ_ls = F.P * v\n",
    "\n",
    "    # Compute the nonzero first order lagrange multiplier estimate by forming\n",
    "    #                  -1\n",
    "    # λ = λ_ls - (A*A^T) *cx\n",
    "\n",
    "    b = -transpose(F.P) * cx\n",
    "    y = zeros(t)\n",
    "    #                -1\n",
    "    # Compute y =(L11) * b\n",
    "    y[1:prankA] = LowerTriangular(transpose(F.R)[1:prankA,1:prankA]) \\ b[1:prankA]\n",
    "    #              -1\n",
    "    # Compute u = R  * y\n",
    "    u = zeros(t)\n",
    "    u[1:prankA] = UpperTriangular(F.R[1:prankA,1:prankA]) \\ y[1:prankA]\n",
    "    λ[:] = λ_ls + F.P * u\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "second_lagrange_mult_estimate! (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LEAST\n",
    "# Compute second order least squares estimate of Lagrange multipliers\n",
    "function second_lagrange_mult_estimate!(\n",
    "    A::Matrix,\n",
    "    J::Matrix,\n",
    "    λ::Vector,\n",
    "    rx::Vector,\n",
    "    p_gn::Vector,\n",
    ")\n",
    "\n",
    "    # Solves the system A^T * λ = Jx^T(r(x) + Jx*p_gn))\n",
    "    (t, n) = size(A)\n",
    "    F = qr(transpose(A), Val(true))\n",
    "    J1 = (J*F.Q)[:, 1:t]\n",
    "    b = transpose(J1) * (rx + J * p_gn)\n",
    "    v = UpperTriangular(F.R) \\ b\n",
    "    λ[:] = F.P * v\n",
    "    return\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_constraint! (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equivalent Fortran : DELETE in dblreduns.f\n",
    "function delete_constraint!(W::WorkingSet,s::Int64)\n",
    "\n",
    "    l,t = W.l, W.t\n",
    "\n",
    "    # Ajout de la contrainte à l'ensemble inactif\n",
    "    W.inactive[l-t+1] = W.active[s]\n",
    "    sort!(@view W.inactive[1:l-t+1])\n",
    "\n",
    "    # Réorganisation de l'ensemble actif\n",
    "    for i = s:t-1\n",
    "        W.active[i] = W.active[i+1]\n",
    "    end\n",
    "    W.active[t] = 0\n",
    "    W.t -= 1\n",
    "    return\n",
    "end\n",
    "\n",
    "# Equivalent Fortran : ADDIT in dblreduns.f\n",
    "function add_constraint!(W::WorkingSet, s::Int64)\n",
    "\n",
    "    l,t = W.l, W.t\n",
    "    # s-th inactive constraint moved from inactive to active set\n",
    "    W.active[t+1] = W.inactive[s]\n",
    "    sort!(@view W.active[1:t+1])\n",
    "    # Inactive set reorganized\n",
    "    for i = s:l-t-1\n",
    "        W.inactive[i] = W.inactive[i+1]\n",
    "    end\n",
    "    W.inactive[l-t] = 0\n",
    "    W.t += 1\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "check_constraint_deletion (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SIGNCH\n",
    "# Returns the index of the constraint that has to be deleted from the working set\n",
    "# Obtainted with the lagrange mulitpliers estimates\n",
    "\n",
    "function check_constraint_deletion(\n",
    "    q::Int64,\n",
    "    A::Matrix,\n",
    "    λ::Vector,\n",
    "    ∇fx::Vector)\n",
    "\n",
    "    t = length(λ)\n",
    "    δ = 10\n",
    "    τ = 0.5\n",
    "    sq_rel = sqrt(eps(Float64))\n",
    "    s = 0\n",
    "    if t > q\n",
    "        e = 0\n",
    "        for i = q+1:t\n",
    "            row_i = norm(A[i,:])\n",
    "            if row_i * λ[i] <= -sq_rel && row_i * λ[i] <= e\n",
    "\n",
    "                e = row_i * λ[i]\n",
    "                s = i\n",
    "            end\n",
    "        end\n",
    "        grad_res = norm(transpose(A) * λ - ∇fx)\n",
    "        if grad_res > -e * δ\n",
    "            s = 0\n",
    "        end\n",
    "    end\n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate_violated_constraints (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EVADD\n",
    "# Move violated constraints to the working set\n",
    "\n",
    "function evaluate_violated_constraints(\n",
    "        cx::Vector,\n",
    "        W::WorkingSet)\n",
    "\n",
    "    # Data\n",
    "    ε = sqrt(eps(Float64))\n",
    "    added = false\n",
    "    if W.l > W.t\n",
    "        i = 1\n",
    "        while i <= W.l - W.t\n",
    "            k = W.inactive[i]\n",
    "            if cx[k] < ε\n",
    "                add_constraint!(W, i)\n",
    "                added = true\n",
    "            else\n",
    "                i += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return added\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_working_set! (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WRKSET\n",
    "# Estimate the lagrange multipliers and eventually delete a constraint from the working set\n",
    "# Compute the search direction using Gauss-Newton method\n",
    "\n",
    "function update_working_set!(\n",
    "    W::WorkingSet,\n",
    "    rx::Vector,\n",
    "    A::Matrix,\n",
    "    C::Constraint,\n",
    "    ∇fx::Vector,\n",
    "    J::Matrix,\n",
    "    p_gn::Vector,\n",
    "    iter_k::Iteration)\n",
    "\n",
    "\n",
    "    λ = Vector{Float64}(undef, W.t)\n",
    "    ε_rank = sqrt(eps(Float64))\n",
    "    first_lagrange_mult_estimate!(C.A, λ, ∇fx,C.cx)\n",
    "    s = check_constraint_deletion(W.q, C.A, λ, ∇fx)\n",
    "\n",
    "    # Constraint number s is deleted from the current working set\n",
    "    if s != 0\n",
    "        # Save s-th element of cx,λ and row s of A to test for feasible direction\n",
    "        cx_s = C.cx[s]\n",
    "        A_s = C.A[s,:]\n",
    "        λ_s = λ[s]\n",
    "        index_s = W.active[s]\n",
    "        deleteat!(λ,s)\n",
    "        deleteat!(C.cx,s)\n",
    "        delete_constraint!(W,s)\n",
    "        iter_k.del = true\n",
    "        iter_k.index_del = index_s\n",
    "        C.A = C.A[setdiff(1:end,s),:]\n",
    "        F_A = qr(transpose(C.A), Val(true))\n",
    "        L11, Q1, P1 = Matrix(transpose(F_A.R)), F_A.Q, F_A.P\n",
    "        rankA = pseudo_rank(diag(L11), ε_rank)\n",
    "        F_L11 = qr(L11, Val(true))\n",
    "        R11, Q2, P2 = F_L11.R, F_L11.Q, F_L11.P\n",
    "\n",
    "        p_gn[:] = gn_search_direction(C.A,J,rx,C.cx,Q1,P1,L11,Q2,P2,R11,rankA,W.t,ε_rank,iter_k)\n",
    "\n",
    "        # Test for feasible direction\n",
    "        As_p = (rankA <= W.t ? 0.0 : dot(A_s,p_gn))\n",
    "        feasible = (As_p >= -cx_s && As_p > 0)\n",
    "\n",
    "        if !feasible\n",
    "            insert!(C.cx,s,cx_s)\n",
    "            insert!(λ,s,λ_s)\n",
    "            s_inact = findfirst(isequal(index_s),W.inactive)\n",
    "            add_constraint!(W,s_inact)\n",
    "            iter_k.index_del = 0\n",
    "            iter_k.del = false\n",
    "            C.A = A[W.active[1:W.t],:]\n",
    "            F_A = qr(transpose(C.A), Val(true))\n",
    "            L11, Q1, P1 = Matrix(transpose(F_A.R)), F_A.Q, F_A.P\n",
    "            rankA = pseudo_rank(diag(L11), ε_rank)\n",
    "            F_L11 = qr(L11, Val(true))\n",
    "            R11, Q2, P2 = F_L11.R, F_L11.Q, F_L11.P\n",
    "            p_gn[:] = gn_search_direction(C.A,J,rx,C.cx,Q1,P1,L11,Q2,P2,R11,rankA,W.t,ε_rank,iter_k)\n",
    "            if !(W.t != rankA || iter_k.rankJ2 != min(m,n-rankA))\n",
    "                second_lagrange_mult_estimate!(C.A,J,λ,rx,p_gn)\n",
    "                s2 = check_constraint_deletion(W.q, C.A, λ, ∇fx)\n",
    "                if s2 != 0\n",
    "                    index_s2 = W.active[s2]\n",
    "                    deleteat!(λ,s2)\n",
    "                    C.cx = C.cx[setdiff(1:end,s2)]\n",
    "                    delete_constraint!(W, s2)\n",
    "                    iter_k.del = true\n",
    "                    iter_k.index_del = index_s2\n",
    "                    C.A = C.A[setdiff(1:end,s2),:]\n",
    "                    F_A = qr(transpose(C.A), Val(true))\n",
    "                    L11, Q1, P1 = Matrix(transpose(F_A.R)), F_A.Q, F_A.P\n",
    "                    rankA = pseudo_rank(diag(L11), ε_rank)\n",
    "                    F_L11 = qr(L11, Val(true))\n",
    "                    R11, Q2, P2 = F_L11.R, F_L11.Q, F_L11.P\n",
    "                    p_gn[:] = gn_search_direction(C.A,J,rx,C.cx,Q1,P1,L11,Q2,P2,R11,rankA,W.t,ε_rank,iter_k)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    # No first order estimate implies deletion of a constraint\n",
    "    elseif s == 0\n",
    "        F_A = qr(transpose(C.A), Val(true))\n",
    "        L11, Q1, P1 = Matrix(transpose(F_A.R)), F_A.Q, F_A.P\n",
    "        rankA = pseudo_rank(diag(L11), ε_rank)\n",
    "        F_L11 = qr(L11, Val(true))\n",
    "        R11, Q2, P2 = F_L11.R, F_L11.Q, F_L11.P\n",
    "        p_gn[:] = gn_search_direction(C.A,J,rx,C.cx,Q1,P1,L11,Q2,P2,R11,rankA,W.t,ε_rank,iter_k)\n",
    "        if !(W.t != rankA || iter_k.rankJ2 != min(m,n-rankA))\n",
    "            second_lagrange_mult_estimate!(C.A,J,λ,rx,p_gn)\n",
    "            s2 = check_constraint_deletion(W.q, C.A, λ, ∇fx)\n",
    "            if s2 != 0\n",
    "                index_s2 = W.active[s2]\n",
    "                deleteat!(λ,s2)\n",
    "                C.cx = C.cx[setdiff(1:end,s2)]\n",
    "                delete_constraint!(W, s2)\n",
    "                iter_k.del = true\n",
    "                iter_k.index_del = index_s2\n",
    "                C.A = C.A[setdiff(1:end,s2),:]\n",
    "                F_A = qr(transpose(C.A), Val(true))\n",
    "                L11, Q1, P1 = Matrix(transpose(F_A.R)), F_A.Q, F_A\n",
    "                rankA = pseudo_rank(diag(L11), ε_rank)\n",
    "                F_L11 = qr(L11, Val(true))\n",
    "                R11, Q2, P2 = F_L11.R, F_L11.Q, F_L11.P\n",
    "                p_gn[:] = gn_search_direction(C.A,J,rx,C.cx,Q1,P1,L11,Q2,P2,R11,rankA,W.t,ε_rank,iter_k)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    iter_k.λ = λ\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init_working_set (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INIALC\n",
    "# Compute the first working set and penalty constants\n",
    "\n",
    "function init_working_set(cx::Vector, K::Array{Array{Float64,1},1}, step::Iteration, q::Int64,l::Int64)\n",
    "    δ, ϵ, ε_rel = 0.1, 0.01, sqrt(eps(Float64))\n",
    "\n",
    "    # Initialisation des pénalités\n",
    "    K[:] = [δ * ones(l) for i=1:length(K)]\n",
    "    for i=1:l\n",
    "        pos = min(abs(cx[i]) + ϵ, δ)\n",
    "        step.w[i] = pos\n",
    "    end\n",
    "\n",
    "    # Determination du premier ensemble actif\n",
    "    active = zeros(Int64, l); inactive = zeros(Int64, l - q)\n",
    "    t = q; lmt = 0\n",
    "\n",
    "    # Les contraintes d'égalité sont toujours actives\n",
    "    active[1:q] = [i for i=1:q]\n",
    "\n",
    "    for i = q+1:l\n",
    "        if cx[i] <= ε_rel\n",
    "            t += 1; active[t] = i\n",
    "        else\n",
    "            lmt += 1; inactive[lmt] = i\n",
    "        end\n",
    "    end\n",
    "    step.t = t\n",
    "    first_working_set = WorkingSet(q, t, l, active, inactive)\n",
    "    return first_working_set\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subspace_min_previous_step (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRESUB\n",
    "# Returns dimension when previous descent direction was computed with subspace minimization\n",
    "\n",
    "function subspace_min_previous_step(\n",
    "    τ::Vector,\n",
    "    ρ::Vector,\n",
    "    ρ_prk::Float64,\n",
    "    c1::Float64,\n",
    "    pseudo_rank::Int64,\n",
    "    previous_dimR::Int64,\n",
    "    progress::Float64,\n",
    "    predicted_linear_progress::Float64,\n",
    "    prelin_previous_dim::Float64,\n",
    "    previous_α::Float64)\n",
    "\n",
    "    # Data\n",
    "\n",
    "    stepb, pgb1, pgb2, predb, rlenb, c2 = 2e-1, 3e-1, 1e-1, 7e-1, 2.0, 1e2\n",
    "\n",
    "    if ((previous_α < step_τ) &&\n",
    "        (progress <= pgb1 * predicted_linear_progress^2) &&\n",
    "        (progress <= pgb2 * prelin_previous_dim^2))\n",
    "\n",
    "        # Bad step\n",
    "        dim = max(1, previous_dimR-1)\n",
    "        if ((previous_dimR > 1) && (ρ[dim] > c1 * ρ_prk))\n",
    "            suggested_dim = dim\n",
    "        end\n",
    "\n",
    "    else\n",
    "        dim = previous_dimR\n",
    "        if (((ρ[dim] > predb * ρ_prk) && (rlenb * τ[dim] < τ[dim+1])) ||\n",
    "            (c2 * τ[dim] < τ[dim+1]))\n",
    "            suggested_dim = dim\n",
    "        else\n",
    "            i1 = previous_dimR-1\n",
    "            buff = [i for i = i1:previous_dimR if ρ[i] > predb * ρ_prk]\n",
    "            suggested_dim = (isempty(buff) ? pseudo_rank : min(buff))\n",
    "        end\n",
    "    end\n",
    "    return suggested_dim\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gn_previous_step (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREGN\n",
    "# Returns dimension to use when previous descent direction was computed with Gauss-Newton method\n",
    "\n",
    "function gn_previous_step(\n",
    "    τ::Vector,\n",
    "    τ_prk::Float64,\n",
    "    mindim::Int64,\n",
    "    ρ::Vector,\n",
    "    ρ_prk::Float64,\n",
    "    pseudo_rank::Int64)\n",
    "\n",
    "    # Data\n",
    "    τ_max, ρ_min = 2e-1, 5e-1\n",
    "    pm1 = pseudo_rank - 1\n",
    "    if mindim > pm1\n",
    "        suggested_dim = mindim\n",
    "    else\n",
    "        k = pm1\n",
    "        while (τ[k] >= τ_max*τ_prk || ρ[k] <= ρ_min*ρ_prk) && k > mindim\n",
    "            k -= 1\n",
    "        end\n",
    "\n",
    "        suggested_dim = (k > mindim ? k : max(mindim, pm1))\n",
    "    end\n",
    "\n",
    "    return suggested_dim\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "check_gn_direction (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GNDCHK\n",
    "# Decides what method should be used to compute the search direction\n",
    "# This information is told by the value returned by method_code :\n",
    "# 1 if Gauss-Newton search direction is accepted\n",
    "# -1 if subspace inimization is suggested\n",
    "# 2 if the method of Newton is suggested\n",
    "\n",
    "# β_k = sqrt(||b1||^2 + ||d1||^2) is an information used to compute the convergence rate\n",
    "\n",
    "function check_gn_direction(\n",
    "    b1nrm::Float64,\n",
    "    d1nrm::Float64,\n",
    "    d1nrm_as_km1::Float64,\n",
    "    dnrm::Float64,\n",
    "    active_c_sum::Float64,\n",
    "    iter_number::Int64,\n",
    "    rankA::Int64,\n",
    "    n::Int64,\n",
    "    m::Int64,\n",
    "    restart::Bool,\n",
    "    constraint_added::Bool,\n",
    "    constraint_deleted::Bool,\n",
    "    W::WorkingSet,\n",
    "    cx::Vector,\n",
    "    λ::Vector,\n",
    "    iter_km1::Iteration)\n",
    "\n",
    "    δ = 1e-1\n",
    "    c1, c2, c3, c4, c5 = 5e-1, 1e-1, 4e0, 1e1, 5e-2\n",
    "    ε_rel = eps(Float64)\n",
    "    β_k = sqrt(d1nrm + b1nrm)\n",
    "\n",
    "    method_code = 1\n",
    "    cond1 = (iter_number == 1 || constraint_added || constraint_deleted)\n",
    "    cond2 = (β_k < c1 * iter_km1.β)\n",
    "    cond3 = ((iter_km1.progress > c2 * iter_km1.predicted_reduction) && ((dnrm <= c3 * β_k)))\n",
    "    if !(cond1 || cond2 || cond3)\n",
    "        method_code = -1\n",
    "        non_linearity_k = sqrt(d1nrm*d1nrm + active_c_sum)\n",
    "             non_linearity_km1 = sqrt(d1nrm_as_km1 + active_c_sum)\n",
    "        to_reduce = false\n",
    "        if W.q < W.t\n",
    "            to_reduce = (to_reduce || any(<(0), λ[W.q+1:W.t]))\n",
    "        end\n",
    "        if (W.l-W.t > 0)\n",
    "            inact_c = [cx[W.inactive[j]] for j = 1:((W.l-W.t))]\n",
    "            to_reduce = (to_reduce || any(<(δ), inact_c))\n",
    "             end\n",
    "        cond4 = active_c_sum > c2\n",
    "        cond5 = (constraint_deleted || constraint_added || to_reduce || (W.t == n && W.t == rankA))\n",
    "        ϵ = max(1e-2, 10.0 * ε_rel)\n",
    "        cond6 = (W.l == W.q) && !((β_k < ϵ*dnrm) || (b1nrm < ϵ && m == n-W.t))\n",
    "\n",
    "        if !(cond4 || cond5 || cond6)\n",
    "            cond7 = (iter_km1.α < c5 && non_linearity_km1 < c2*non_linearity_k) || m == n-W.t\n",
    "            cond8 = !(dnrm <= c4*β_k)\n",
    "            if cond7 || cond8\n",
    "                method_code = 2\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return method_code, β_k\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "determine_solving_dim (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DIMUPP\n",
    "# Determine suitable dimension for solving the system Rx = y\n",
    "# (i.e how many columns of R should be used)\n",
    "# where R is rankR*rankR Upper Triangular\n",
    "# Returns the dimension and a real scalar containing 1.0 when restart is false\n",
    "# or L(previous_dimR-1)/L(previous_dimR)\n",
    "# where L(i) is the length of an estimated search direction computed by using dimension i\n",
    "\n",
    "function determine_solving_dim(\n",
    "    previous_dimR::Int64,\n",
    "    rankR::Int64,\n",
    "    predicted_linear_progress::Float64,\n",
    "    obj_progress::Float64,\n",
    "    prelin_previous_dim::Float64,\n",
    "    R::UpperTriangular{Float64,Array{Float64,2}},\n",
    "    y::Vector,\n",
    "    previous_α::Float64,\n",
    "    restart::Bool)\n",
    "\n",
    "    newdim = rankR\n",
    "    η = 1.0\n",
    "    mindim = 1\n",
    "    if rankR > 0\n",
    "        l_estim_sd, l_estim_righthand = zeros(rankR), zeros(rankR)\n",
    "        l_estim_sd[1] = abs(y[1])\n",
    "        l_estim_righthand[1] = abs(y[1] / R[1,1])\n",
    "\n",
    "        if rankR > 1\n",
    "            for i = 2:rankR\n",
    "                l_estim_sd[i] = y[i]\n",
    "                l_estim_righthand[i] = y[i] / R[i,i]\n",
    "                l_estim_righthand[i] = norm(l_estim_righthand[i-1:i])\n",
    "                l_estim_sd[i] = norm(l_estim_sd[i-1:i])\n",
    "            end\n",
    "        end\n",
    "\n",
    "        nrm_estim_sd = l_estim_sd[rankR]\n",
    "        nrm_estim_righthand = l_estim_righthand[rankR]\n",
    "\n",
    "        # Determine lowest possible dimension\n",
    "\n",
    "        dsum = 0.0\n",
    "        psimax = 0.0\n",
    "        for i = 1:rankR\n",
    "            dsum += l_estim_sd[i]^2\n",
    "            psi = sqrt(dsum) * abs(R[i,i])\n",
    "            if psi > psimax\n",
    "                psimax = psi\n",
    "                mindim = i\n",
    "            end\n",
    "        end\n",
    "\n",
    "        k = mindim\n",
    "        if !restart\n",
    "            if previous_dimR == rankR || previous_dimR <= 0\n",
    "                # Gauss-Newton at previous step\n",
    "                suggested_dim = gn_previous_step(l_estim_sd, nrm_estim_sd, mindim, l_estim_righthand, nrm_estim_righthand, rankR)\n",
    "\n",
    "            elseif previous_dimR != rankR && rankR > 0\n",
    "                # Subbspace-Minimization at previous step\n",
    "                suggested_dim = subspace_min_previous_step(l_estim_sd,l_estim_righthand,nrm_estim_righthand,\n",
    "                    c1,rankR,previous_dimR,obj_progress,predicted_linear_progress,\n",
    "                    prelin_previous_dim,previous_α)\n",
    "            end\n",
    "            newdim = max(mindim,suggested_dim)\n",
    "        end\n",
    "\n",
    "        newdim = max(0, min(rankR, previous_dimR))\n",
    "        if newdim != 0\n",
    "            k = max(previous_dimR-1, 1)\n",
    "            if l_estim_sd[newdim] != 0\n",
    "                η = l_estim_sd[k] / l_estim_sd[newdim]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return newdim, η\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "choose_subspace_dimensions (generic function with 2 methods)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SUBSPC\n",
    "# Computes the dimensions of the subspaces where minimization should be done\n",
    "\n",
    "function choose_subspace_dimensions(\n",
    "        rx_sum::Float64,\n",
    "        rx::Vector,\n",
    "        active_cx_sum::Float64,\n",
    "        J1::Matrix,\n",
    "        m::Int64,\n",
    "        n::Int64,\n",
    "        t::Int64,\n",
    "        rankJ2::Int64,\n",
    "        rankA::Int64,\n",
    "        b::Vector,\n",
    "        Q1,\n",
    "        R11::Matrix,\n",
    "        P2::Matrix,\n",
    "        Q3,\n",
    "        P3::Matrix,\n",
    "        R22::Matrix,\n",
    "        previous_iter::Iteration,\n",
    "        restart::Bool = false)\n",
    "\n",
    "    # Data\n",
    "    β1, β2, α_low = 0.1, 0.1, 0.2\n",
    "    previous_α = previous_iter.α\n",
    "\n",
    "    if rankA <= 0\n",
    "        dimA = 0\n",
    "        previous_dimA = 0\n",
    "        η_A = 1.0\n",
    "        d = -rx\n",
    "\n",
    "    elseif rankA > 0\n",
    "        previous_dimA = abs(previous_iter.dimA) + t - previous_iter.t\n",
    "        nrm_b_asprev = norm(b[1:previous_dimA])\n",
    "        nrm_b = norm(b)\n",
    "        constraint_progress = dot(previous_iter.cx,previous_iter.cx) - active_cx_sum\n",
    "\n",
    "        # Determine Dimension for matrix R11 to be used\n",
    "        dimA, η_A = determine_solving_dim(previous_dimA,rankA,nrm_b,constraint_progress,nrm_b_asprev,UpperTriangular(R11),b,previous_α,restart)\n",
    "\n",
    "        # Solve for p1 the system R11*P2*p1 = b\n",
    "        # Using dimA columns of R11\n",
    "        # Forms right hand side d = r(x)+J1*p1\n",
    "\n",
    "        δp1 = UpperTriangular(R11[1:dimA,1:dimA]) \\ b[1:dimA]\n",
    "        p1 = P2[1:rankA,1:rankA] * [δp1;zeros(rankA-dimA)]\n",
    "        d = -(rx + J1*p1)\n",
    "    end\n",
    "\n",
    "    if rankJ2 > 0 d = transpose(Q3)*d end\n",
    "\n",
    "    previous_dimJ2 = abs(previous_iter.dimJ2) + t - previous_iter.t\n",
    "    nrm_d_asprev = norm(d[1:previous_dimJ2])\n",
    "    nrm_d = norm(d)\n",
    "    residual_progress = dot(previous_iter.rx, previous_iter.rx) - rx_sum\n",
    "    dimJ2, η_J2 = determine_solving_dim(previous_dimJ2,rankJ2,nrm_d,residual_progress,nrm_d_asprev,UpperTriangular(R22),d,previous_α,restart)\n",
    "\n",
    "    if !restart && previous_α >= α_low\n",
    "        dimA = max(dimA, previous_dimA)\n",
    "        dimJ2 = max(dimJ2, previous_dimJ2)\n",
    "    end\n",
    "    return dimA, dimJ2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "search_direction_analys! (generic function with 2 methods)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANALYS\n",
    "# Check if the latest step was sufficientlt good and eventually\n",
    "# recompute the search direction by using either subspace minimization\n",
    "# or the method of Newton\n",
    "\n",
    "function search_direction_analys!(\n",
    "        previous_iter::Iteration,\n",
    "        current_iter::Iteration,\n",
    "        iter_number::Int64,\n",
    "        x::Vector,\n",
    "        c::ConstraintsEval,\n",
    "        r::ResidualsEval,\n",
    "        rx::Vector,\n",
    "        cx::Vector,\n",
    "        active_cx::Vector,\n",
    "        λ::Vector,\n",
    "        rx_sum::Float64,\n",
    "        active_cx_sum::Float64,\n",
    "        p_gn::Vector,\n",
    "        d_gn::Vector,\n",
    "        b_gn::Vector,\n",
    "        nrm_b1_gn::Float64,\n",
    "        nrm_d1_gn::Float64,\n",
    "        nrm_d_gn::Float64,\n",
    "        J::Matrix,\n",
    "        m::Int64,\n",
    "        n::Int64,\n",
    "        working_set::WorkingSet,\n",
    "        rankA::Int64,\n",
    "        rankJ2::Int64,\n",
    "        P1::Matrix,\n",
    "        Q1,\n",
    "        L11::Matrix,\n",
    "        P2::Matrix,\n",
    "        Q2,\n",
    "        R11::Matrix,\n",
    "        P3::Matrix,\n",
    "        Q3,\n",
    "        R22::Matrix,\n",
    "        constraint_added::Bool,\n",
    "        constraint_deleted::Bool,\n",
    "        restart::Bool = false)\n",
    "\n",
    "\n",
    "    prev_dimJ2m1 = previous_iter.dimJ2 + previous_iter.t - working_set.t - 1\n",
    "    nrm_d1_asprev = norm(d_gn[1:prev_dimJ2m1])\n",
    "\n",
    "\n",
    "\n",
    "    method_code, β = check_gn_direction(nrm_b1_gn, nrm_d1_gn, nrm_d1_asprev, nrm_d_gn, active_cx_sum, iter_number, rankA, n, m, restart, constraint_added, constraint_deleted, working_set, cx, λ, previous_iter)\n",
    "\n",
    "\n",
    "    # Gauss-Newton accepted\n",
    "    if method_code == 1\n",
    "        dimA = rankA\n",
    "        dimJ2 = rankJ2\n",
    "        p, b, d = p_gn, b_gn, d_gn\n",
    "\n",
    "    # Subspace minimization to recompute the search direction\n",
    "    # using dimA columns of matrix R11 and dimJ2 columns of matrix R22\n",
    "    elseif method_code == -1\n",
    "        JQ1 = J*Q1\n",
    "        J1, J2 = JQ1[:,1:rankA], JQ1[:,rankA+1:end]\n",
    "        b = -transpose(Q2)*transpose(P1)*active_cx\n",
    "        dimA, dimJ2 = choose_subspace_dimensions(rx_sum,rx, active_cx_sum, J1, m, n, working_set.t, rankJ2, rankA, b, Q1, R11, P2, Q3, P3, R22, previous_iter, restart)\n",
    "        p, b, d = sub_search_direction(J1, J2, rx, active_cx, Q1, P1, L11, Q2, P2, R11, Q3, R22, P3, n, working_set.t,rankA, dimA, dimJ2, method_code)\n",
    "\n",
    "\n",
    "\n",
    "    # Search direction computed with the method of Newton\n",
    "    elseif method_code == 2\n",
    "        p = newton_search_direction(x,c,r,active_cx,working_set.active,n,m,working_set.l,working_set.t,λ,rx,J,Q1,P1,L11,Q2,R11,P2,rankA)\n",
    "        b, d = b_gn, d_gn\n",
    "        dimA = -working_set.t\n",
    "        dimJ2 = working_set.t - n\n",
    "    end\n",
    "    current_iter.b_gn = b\n",
    "    current_iter.d_gn = d\n",
    "    current_iter.dimA = dimA\n",
    "    current_iter.dimJ2 = dimJ2\n",
    "    current_iter.code = method_code\n",
    "    current_iter.β = β\n",
    "    current_iter.p = p\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "psi (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function psi(\n",
    "    x::Vector,\n",
    "    α::Float64,\n",
    "    p::Vector,\n",
    "    r::ResidualsEval,\n",
    "    c::ConstraintsEval,\n",
    "    w::Vector,\n",
    "    m::Int64,\n",
    "    l::Int64,\n",
    "    t::Int64,\n",
    "    active::Vector,\n",
    "    inactive::Vector)\n",
    "\n",
    "\n",
    "    r.ctrl,c.ctrl = 1,1\n",
    "\n",
    "    r_new, c_new = zeros(m), zeros(l)\n",
    "    dummy = zeros((1,1))\n",
    "\n",
    "    penalty_constraint_sum = 0.0\n",
    "    x_new = x + α*p\n",
    "    r(x_new,r_new,dummy)\n",
    "    c(x_new,c_new,dummy)\n",
    "    # First part of sum with active constraints\n",
    "    for i = 1:t\n",
    "        j = active[i]\n",
    "        penalty_constraint_sum += w[j] * c_new[j]^2\n",
    "    end\n",
    "\n",
    "    # Second part of sum with inactive constraints\n",
    "    for i = 1:l-t\n",
    "        j = inactive[i]\n",
    "        if c_new[j] < 0.0\n",
    "            penalty_constraint_sum  += w[j] * c_new[j]^2\n",
    "        end\n",
    "    end\n",
    "    return 0.5 * (dot(r_new,r_new) + penalty_constraint_sum)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_norm_weight_update! (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAXNRM\n",
    "# Update the penalty weights corresponding to the\n",
    "# constraints in the current working setb\n",
    "\n",
    "function max_norm_weight_update!(\n",
    "        nrm2_Ap::Float64,\n",
    "        rmy::Float64,\n",
    "        α_w::Float64,\n",
    "        δ::Float64,\n",
    "        w::Vector,\n",
    "        active::Vector,\n",
    "        t::Int64,\n",
    "        K::Array{Array{Float64,1},1}\n",
    ")\n",
    "    μ = (abs(α_w-1.0) <= δ ? 0.0 : rmy / nrm2_Ap)\n",
    "    i1 = (active[1] != 0 ? active[1] : 1)\n",
    "\n",
    "    previous_w = w[i1]\n",
    "    ν = max(μ, K[4][1])\n",
    "    for i = 1:t\n",
    "        k = active[i]\n",
    "        w[k] = ν\n",
    "    end\n",
    "\n",
    "    if μ > previous_w\n",
    "        mu_not_placed = true\n",
    "        i = 1\n",
    "        while i <= 4 && mu_not_placed\n",
    "            if μ > K[i][1]\n",
    "                for j = 4:-1:i+1\n",
    "                    K[j][1] = K[j-1][1]\n",
    "                end\n",
    "                K[i][1] = μ\n",
    "                mu_not_placed = false\n",
    "            end\n",
    "            i += 1\n",
    "        end\n",
    "    end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "penalty_weight_update (generic function with 2 methods)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function penalty_weight_update(\n",
    "        w_old::Vector,\n",
    "        Jp::Vector,\n",
    "        Ap::Vector,\n",
    "        K::Array{Array{Float64,1},1},\n",
    "        rx::Vector,\n",
    "        rx_sum::Float64,\n",
    "        cx::Vector,\n",
    "        active::Vector,\n",
    "        t::Int64,\n",
    "        dimA::Int64,\n",
    "        norm_code::Int64 = 0)\n",
    "    # Data\n",
    "    δ = 0.25\n",
    "    w = w_old[:]\n",
    "\n",
    "    nrm2_Ap = dot(Ap,Ap)\n",
    "    nrm2_Jp = dot(Jp,Jp)\n",
    "    Jp_rx = dot(Jp,rx)\n",
    "\n",
    "    AtwA = 0.\n",
    "    BtwA = 0.\n",
    "    if dimA > 0\n",
    "        for i = 1:dimA\n",
    "            k = active[i]\n",
    "            AtwA += w[k] * Ap[i]^2\n",
    "            BtwA += w[k] * Ap[i] * cx[k]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    α_w = 1.0\n",
    "    if abs(AtwA + nrm2_Jp) > eps(Float64)\n",
    "        α_w = (-BtwA - Jp_rx) / (AtwA + nrm2_Jp)\n",
    "    end\n",
    "\n",
    "    rmy = (abs(Jp_rx + nrm2_Jp) / δ) - nrm2_Jp\n",
    "    if norm_code == 0\n",
    "        max_norm_weight_update!(nrm2_Ap, rmy, α_w, δ, w, active, t, K)\n",
    "    end\n",
    "    # TODO: add weight update using euclidean norm method\n",
    "\n",
    "    #                               T                           T\n",
    "    # Computation of ψ'(0) = [J(x)p] r(x)+   Σ      w_i*[∇c_i(x) p]c_i(x)\n",
    "    #                                     i ∈ active\n",
    "    BtwA = 0.0\n",
    "    for i=1:t\n",
    "        k = active[i]\n",
    "        BtwA += w[k] * Ap[i] * cx[k]\n",
    "    end\n",
    "    dψ0 = BtwA + Jp_rx\n",
    "    return w, dψ0\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concatenate! (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONCAT\n",
    "# Compute in place the components of vector v used for polynomial minimization\n",
    "\n",
    "function concatenate!(v::Vector,\n",
    "                      rx::Vector,\n",
    "                      cx::Vector,\n",
    "                      w::Vector,\n",
    "                      m::Int64,\n",
    "                      t::Int64,\n",
    "                      l::Int64,\n",
    "                      active::Vector,\n",
    "                      inactive::Vector)\n",
    "\n",
    "    v[1:m] = rx[:]\n",
    "    if t != 0\n",
    "        for i = 1:t\n",
    "            k = active[i]\n",
    "            v[m+k] = sqrt(w[k]) * cx[k]\n",
    "        end\n",
    "    end\n",
    "    if l != 0\n",
    "        for j = 1:l-t\n",
    "            k = inactive[j]\n",
    "            v[m+k] = (cx[k] > 0 ? 0.0 : sqrt(w[k]) * cx[k])\n",
    "        end\n",
    "    end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coefficients_linesearch! (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LINC2\n",
    "# Compute in place vectors v0 and v2 so that one dimensional minimization in R^m can be done\n",
    "# Also modifies components of v1 related to constraints\n",
    "\n",
    "function coefficients_linesearch!(v0::Vector,\n",
    "                                 v1::Vector,\n",
    "                                 v2::Vector,\n",
    "                                 α_k::Float64,\n",
    "                                 rx::Vector,\n",
    "                                 cx::Vector,\n",
    "                                 rx_new::Vector,\n",
    "                                 cx_new::Vector,\n",
    "                                 w::Vector,\n",
    "                                 m::Int64,\n",
    "                                 t::Int64,\n",
    "                                 l::Int64,\n",
    "                                 active::Vector,\n",
    "                                 inactive::Vector)\n",
    "\n",
    "    # Compute v0\n",
    "    concatenate!(v0,rx,cx,w,m,t,l,active,inactive)\n",
    "\n",
    "    v_buff = zeros(m+l)\n",
    "    concatenate!(v_buff,rx_new,cx_new,w,m,t,l,active,inactive)\n",
    "\n",
    "    # Computation of v2 components\n",
    "    v2[:] = ((v_buff - v0) / α_k - v1) / α_k\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minimize_quadratic (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUAMIN\n",
    "\n",
    "function minimize_quadratic(x1::Float64, y1::Float64,\n",
    "                            x2::Float64, y2::Float64,\n",
    "                            x3::Float64, y3::Float64)\n",
    "\n",
    "    d1, d2 = y2 - y1, y3 - y1\n",
    "    s = (x3 - x1)^2 * d1 - (x2 - x1)^2 * d2\n",
    "    q = 2 * ((x2 - x1) * d2 - (x3 - x1) * d1)\n",
    "    return x1 - s / q\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minrn (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MINRN\n",
    "\n",
    "\n",
    "function minrn(x1::Float64, y1::Float64,\n",
    "               x2::Float64, y2::Float64,\n",
    "               x3::Float64, y3::Float64,\n",
    "               α_min::Float64,\n",
    "               α_max::Float64,\n",
    "               p_max::Float64)\n",
    "\n",
    "    ε = sqrt(eps(Float64)) / p_max\n",
    "\n",
    "    # α not computable\n",
    "    # Add an error in this case\n",
    "    if abs(x1 - x2) < ε || abs(x3 - x1) < ε || abs(x3 - x2) < ε\n",
    "        α, pα = 0., 0.\n",
    "\n",
    "    else\n",
    "    # Compute minimum of quadradic passing through y1, y2 and y3\n",
    "    # respectively at points x1, x2 and x3\n",
    "        u = minimize_quadratic(x1, y1, x2, y2, x3, y3)\n",
    "        α = clamp(u, α_min, α_max)\n",
    "        t1 = (α - x1) * (α - x2) * y3 / ((x3 - x1) * (x3 - x2))\n",
    "        t2 = (α - x3) * (α - x2) * y1 / ((x1 - x3) * (x1 - x2))\n",
    "        t3 = (α - x3) * (α - x2) * y2 / ((x2 - x1) * (x2 - x3))\n",
    "\n",
    "        # Value of the estimation of ψ(α)\n",
    "        pα = t1 + t2 + t3\n",
    "    end\n",
    "\n",
    "    return α, pα\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newton_raphson (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function parameters_rm(\n",
    "    v0::Vector,\n",
    "    v1::Vector,\n",
    "    v2::Vector,\n",
    "    x_min::Float64,\n",
    "    ds::Polynomial{Float64},\n",
    "    dds::Polynomial{Float64})\n",
    "\n",
    "    dds_best = dds(x_min)\n",
    "    η, d = 0.1, 1.\n",
    "    normv2 = dot(v2, v2)\n",
    "    h0 = abs(ds(x_min) / dds_best)\n",
    "    Dm = abs(6 * dot(v1,v2) + 12 * x_min*normv2) + 24 * h0 * normv2\n",
    "    hm = max(h0, 1)\n",
    "\n",
    "    # s'(α) = 0 is solved analytically\n",
    "    if dds_best * η < 2 * Dm * hm\n",
    "\n",
    "        # If t = α+a1 solves t^3 + b*t + c = O then α solves s'(α) = 0\n",
    "        (a3, a2, a1) = coeffs(ds) / (2 * normv2)\n",
    "\n",
    "        b = a2 - (a1^2) / 3\n",
    "        c = a3 - a1 * a2/3 + 2*(a1/3)^3\n",
    "        d = (c/2)^2 + (b/3)^3\n",
    "        # Two interisting roots\n",
    "        if d < 0\n",
    "            α_hat, β_hat = two_roots(b, c, d, a1, x_min)\n",
    "\n",
    "        # Only one root is computed\n",
    "        else\n",
    "            α_hat = one_root(c, d, a1)\n",
    "        end\n",
    "\n",
    "    # s'(α) = 0 is solved using Newton-Raphson's method\n",
    "    else\n",
    "        α_hat = newton_raphson(x_min, Dm, ds, dds)\n",
    "    end\n",
    "\n",
    "    # If only one root computed\n",
    "    if d >= 0\n",
    "        β_hat = α_hat\n",
    "    end\n",
    "    return α_hat, β_hat\n",
    "\n",
    "end\n",
    "\n",
    "function bounds(α_min::Float64, \n",
    "        α_max::Float64, \n",
    "        α::Float64, \n",
    "        s::Polynomial{Float64})\n",
    "    \n",
    "    α = min(α, α_max)\n",
    "    α = max(α, α_min)\n",
    "    return α, s(α)\n",
    "end\n",
    "\n",
    "function newton_raphson(\n",
    "    x_min::Float64,\n",
    "    Dm::Float64,\n",
    "    ds::Polynomial{Float64},\n",
    "    dds::Polynomial{Float64})\n",
    "\n",
    "    α, newton_iter = x_min, 0\n",
    "    ε, error = 1e-4, 1.\n",
    "    while error > ε || newton_iter < 3\n",
    "        c = dds(α)\n",
    "        h = -ds(α) / c\n",
    "        α += h\n",
    "        error = (2 * Dm * h^2) / abs(c)\n",
    "        newton_iter += 1\n",
    "    end\n",
    "    return α\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "two_roots (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equivalent Fortran : ONER in dblreduns.f\n",
    "function one_root(c::Float64, \n",
    "        d::Float64, \n",
    "        a::Float64)\n",
    "    arg1, arg2 = -c/2 + sqrt(d), -c/2 - sqrt(d)\n",
    "    return cbrt(arg1) + cbrt(arg2) - a/3\n",
    "end\n",
    "\n",
    "# Equivalent Fortran : TWOR in dblreduns.f\n",
    "function two_roots(b::Float64, \n",
    "        c::Float64, \n",
    "        d::Float64, \n",
    "        a::Float64, \n",
    "        x_min::Float64)\n",
    "    φ = acos(abs(c/2) / (-b/3)^(3/2))\n",
    "    t = (c <= 0 ? 2*sqrt(-b/3) : -2*sqrt(-b/3))\n",
    "\n",
    "    # β1 is the global minimizer of s(α).\n",
    "    # If d is close to zero the root β1 is stable while β2 and β3 become unstable\n",
    "    β1 = t * cos(φ/3) - a/3\n",
    "    β2 = t * cos((φ + 2 * π) / 3) - a/3\n",
    "    β3 = t * cos((φ + 4 * π) / 3) - a/3\n",
    "\n",
    "    # Sort β1, β2 and β3 so that β1 <= β2 <= β3\n",
    "    β1, β2, β3 = sort([β1, β2, β3])\n",
    "\n",
    "    #β1 or β3 are now the roots of interest\n",
    "    α, β = (x_min <= β2 ? (β1, β3) : (β3, β1))\n",
    "    return α, β\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minrm (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equivalent Fortran : MINRM in dblreduns.f\n",
    "function minrm(\n",
    "    v0::Vector,\n",
    "    v1::Vector,\n",
    "    v2::Vector,\n",
    "    x_min::Float64,\n",
    "    α_min::Float64,\n",
    "    α_max::Float64)\n",
    "\n",
    "    s = Polynomial([0.5 * dot(v0,v0), dot(v0,v1), dot(v0,v2) + 0.5 * dot(v1,v1), dot(v1,v2), 0.5 * dot(v2,v2)])\n",
    "    ds = derivative(s)\n",
    "    dds = derivative(ds)\n",
    "    α_hat, β_hat = parameters_rm(v0, v1, v2, x_min, ds, dds)\n",
    "    sα, sβ = s(α_hat), s(β_hat)\n",
    "    α_old = α_hat\n",
    "    α_hat, sα = bounds(α_min, α_max, α_hat, s)\n",
    "    if α_old == β_hat\n",
    "        β_hat, sβ = α_hat, s(α_hat)\n",
    "    else\n",
    "        β_hat, sβ = bounds(α_min, α_max, β_hat, s)\n",
    "    end\n",
    "    return α_hat, sα, β_hat, sβ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "check_reduction (generic function with 1 method)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REDC\n",
    "# Returns true if essential reduction in the objective function is likely\n",
    "# Otherwise returns false\n",
    "\n",
    "function check_reduction(\n",
    "    α::Float64,\n",
    "    ψ_α::Float64,\n",
    "    α_k::Float64,\n",
    "    ψ_k::Float64,\n",
    "    approx_k::Float64,\n",
    "    η::Float64,\n",
    "    diff_psi::Float64)\n",
    "\n",
    "    # Data\n",
    "    δ = 0.2\n",
    "\n",
    "    if ψ_α - approx_k >= η * diff_psi\n",
    "        # println(\"ψ_k = $ψ_k\")\n",
    "        reduction_likely = !((ψ_α - ψ_k < η * diff_psi) && (ψ_k > δ * ψ_α))\n",
    "    else\n",
    "        reduction_likely = false\n",
    "    end\n",
    "    return reduction_likely\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "goldstein_armijo_step (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GAC\n",
    "# Halfs the value of u until a Goldstein-Armijo condition is satisfied\n",
    "# or until steplength times search direction is below square root of relative_prevision\n",
    "\n",
    "function goldstein_armijo_step(\n",
    "    ψ0::Float64,\n",
    "    dψ0::Float64,\n",
    "    α_min::Float64,\n",
    "    τ::Float64,\n",
    "    p_max::Float64,\n",
    "    x::Vector,\n",
    "    α0::Float64,\n",
    "    p::Vector,\n",
    "    r::ResidualsEval ,\n",
    "    c::ConstraintsEval,\n",
    "    w::Vector,\n",
    "    m::Int64,\n",
    "    l::Int64,\n",
    "    t::Int64,\n",
    "    active::Vector,\n",
    "    inactive::Vector)\n",
    "\n",
    "    u = α0\n",
    "    sqr_ε = sqrt(eps(Float64))\n",
    "    exit = (p_max*u < sqr_ε) || (u <= α_min)\n",
    "    ψu = psi(x,u,p,r,c,w,m,l,t,active,inactive)\n",
    "    while !exit && (ψu > ψ0 + τ*u*dψ0)\n",
    "        u *= 0.5\n",
    "        ψu = psi(x,u,p,r,c,w,m,l,t,active,inactive)\n",
    "        exit = (p_max*u < sqr_ε) || (u <= α_min)\n",
    "    end\n",
    "    return u\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linesearch_constrained (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LINEC\n",
    "# Linesearch routine for constrained least squares problems\n",
    "# Compute the steplength α (\\alpha) for the iteration x_new = x + αp\n",
    "# x current point, p search direction\n",
    "#\n",
    "# α is close to the solution of the problem\n",
    "# min ψ(α)\n",
    "# with α_low <= α <= α_upp\n",
    "#\n",
    "# ψ(α) = 0.5 * (||r(x+αp)||^2 + Σ (w_i * c_i(x+αp)^2) +  Σ min(0,w_j * c_j(x+αp))^2)\n",
    "#                               i                        j\n",
    "# i correspond to constraints in current working set, j to inactive constraints\n",
    "\n",
    "function linesearch_constrained(\n",
    "    x::Vector,\n",
    "    α0::Float64,\n",
    "    p::Vector,\n",
    "    r::ResidualsEval,\n",
    "    c::ConstraintsEval,\n",
    "    rx::Vector,\n",
    "    cx::Vector,\n",
    "    JpAp::Vector,\n",
    "    w::Vector,\n",
    "    m::Int64,\n",
    "    l::Int64,\n",
    "    t::Int64,\n",
    "    active::Vector,\n",
    "    inactive::Vector,\n",
    "    ψ0::Float64,\n",
    "    dψ0::Float64,\n",
    "    α_low::Float64,\n",
    "    α_upp::Float64)\n",
    "\n",
    "    # Only evalutations for residuals and constraints\n",
    "    r.ctrl = 1\n",
    "    c.ctrl = 1\n",
    "    dummy = zeros((1,1))\n",
    "\n",
    "    # LINC1\n",
    "    # Set values of constants and compute α_min, α_max and α_k\n",
    "\n",
    "    η = 0.3 # \\eta\n",
    "    τ = 0.25 # \\tau\n",
    "    γ = 0.4 # \\gamma\n",
    "\n",
    "    α_min, α_max = α_low, α_upp\n",
    "    α_k = min(α0, α_max)\n",
    "    α_km1 = 0.0\n",
    "    ψ_km1 = ψ0\n",
    "    p_max = norm(p,Inf)\n",
    "\n",
    "    # LINC2\n",
    "    # Computation of v1\n",
    "    v1 = JpAp\n",
    "    if t != 0\n",
    "        for i = 1:t\n",
    "            k = active[i]\n",
    "            v1[m+k] = sqrt(w[k]) * v1[m+k]\n",
    "        end\n",
    "    end\n",
    "    if l-t != 0\n",
    "        for j = 1:l-t\n",
    "            k = inactive[j]\n",
    "            v1[m+k] = (cx[k] > 0 ? 0.0 : sqrt(w[k]) * v1[m+k])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    ψ_k = psi(x,α_k,p,r,c,w,m,l,t,active,inactive)\n",
    "\n",
    "    diff_psi = ψ0 - ψ_k\n",
    "\n",
    "    rx_new, cx_new = zeros(m), zeros(l)\n",
    "    r(x+α_k*p,rx_new,dummy)\n",
    "    c(x+α_k*p,cx_new,dummy)\n",
    "\n",
    "    v0,v2 = zeros(m+l), zeros(m+l)\n",
    "    coefficients_linesearch!(v0,v1,v2,α_k,rx,cx,rx_new,cx_new,w,m,t,l,active,inactive)\n",
    "\n",
    "    # Set x_min = the best of the points 0 and α0\n",
    "\n",
    "    x_min = (diff_psi >= 0 ? α_k : 0.0)\n",
    "\n",
    "    # Minimize in R^m. Use two points 0 and α0\n",
    "    # New suggestion of steplength is α_kp1 (stands for \"k+1\")\n",
    "    # pk is the value of the approximating function at α_kp1\n",
    "\n",
    "    α_kp1, pk, β, pβ = minrm(v0,v1,v2,x_min,α_min,α_max)\n",
    "\n",
    "\n",
    "    if α_kp1 != β && pβ < pk && β <= α_k\n",
    "        α_kp1 = β\n",
    "        pk = pβ\n",
    "    end\n",
    "\n",
    "    # UPDATE\n",
    "\n",
    "    α_km2 = α_km1\n",
    "    ψ_km2 = ψ_km1\n",
    "    α_km1 = α_k\n",
    "    ψ_km1 = ψ_k\n",
    "    α_k = α_kp1\n",
    "    ψ_k = psi(x,α_k,p,r,c,w,m,l,t,active,inactive)\n",
    "\n",
    "    # Test termination condition at α0\n",
    "    if (-diff_psi <= τ * dψ0 * α_km1) || (ψ_km1 < γ * ψ0)\n",
    "        # Termination condition satisfied at α0\n",
    "        diff_psi = ψ0 - ψ_k\n",
    "\n",
    "        # REDUCE\n",
    "        # Check if essential reduction is likely\n",
    "        reduction_likely = check_reduction(α_km1,ψ_km1,α_k,ψ_k,pk,η,diff_psi)\n",
    "\n",
    "        while reduction_likely\n",
    "            # Value of the objective function can most likely be reduced\n",
    "            # Minimize in R^n using 3 points : α_km2, α_km1 and α_k\n",
    "            # New suggestion of the steplength is α_kp1, pk is its approximated value\n",
    "            α_kp1, pk = minrn(α_k,ψ_k,α_km1,ψ_km1,α_km2,ψ_km2,α_min,α_max,p_max)\n",
    "\n",
    "            # UPDATE\n",
    "            α_km2 = α_km1\n",
    "            ψ_km2 = ψ_km1\n",
    "            α_km1 = α_k\n",
    "            ψ_km1 = ψ_k\n",
    "            α_k = α_kp1\n",
    "            ψ_k = psi(x,α_k,p,r,c,w,m,l,t,active,inactive)\n",
    "            diff_psi = ψ0 - ψ_k\n",
    "            reduction_likely = check_reduction(α_km1,ψ_km1,α_k,ψ_k,pk,η,diff_psi)\n",
    "        end\n",
    "        # println(\"No more reduction required\")\n",
    "        # Terminate but choose the best point out of α_km1 and α_k\n",
    "        if (ψ_km1 - pk >= η * diff_psi) && (ψ_k < ψ_km1)\n",
    "            α_km1 = α_k\n",
    "            ψ_km1 = ψ_k\n",
    "        end\n",
    "    # Termination condition not satisfied at α0\n",
    "    else\n",
    "        diff_psi = ψ0 - ψ_k\n",
    "        # Test termination condition at α1, i.e. α_k\n",
    "        if (-diff_psi <= τ * dψ0 * α_k) || (ψ_k < γ * ψ0)\n",
    "            # Termination condition satisfied at α1\n",
    "            # Check if α0 is somewhat good\n",
    "            if ψ0 <= ψ_km1\n",
    "                x_min = α_k\n",
    "                r(x+α_k*p,rx_new,dummy)\n",
    "                c(x+α_k*p,cx_new,dummy)\n",
    "                v0,v2 = zeros(m+l), zeros(m+l)\n",
    "                coefficients_linesearch!(v0,v1,v2,α_k,rx,cx,rx_new,cx_new,w,m,t,l,active,inactive)\n",
    "                α_kp1, pk, β, pβ = minrm(v0,v1,v2,x_min,α_min,α_max)\n",
    "                if α_kp1 != β && pβ < pk && β <= α_k\n",
    "                    α_kp1 = β\n",
    "                    pk = pβ\n",
    "                end\n",
    "                α_km1 = 0.0\n",
    "                ψ_km1 = ψ0\n",
    "\n",
    "            else\n",
    "                # Minimize in R^n. use 3 points : 0, α0 and α1\n",
    "                # New suggestion of the steplength is α_kp1\n",
    "                # pk is the value of the approximating function at α_kp1\n",
    "                α_kp1, pk = minrn(α_k,ψ_k,α_km1,ψ_km1,α_km2,ψ_km2,α_min,α_max,p_max)\n",
    "            end\n",
    "            diff = ψ0 - ψ_k\n",
    "\n",
    "            # UPDATE\n",
    "            α_km2 = α_km1\n",
    "            ψ_km2 = ψ_km1\n",
    "            α_km1 = α_k\n",
    "            ψ_km1 = ψ_k\n",
    "            α_k = α_kp1\n",
    "            ψ_k = psi(x,α_k,p,r,c,w,m,l,t,active,inactive)\n",
    "\n",
    "            # Check if essential reduction is likely\n",
    "            reduction_likely = check_reduction(α_km1,ψ_km1,α_k,ψ_k,pk,η,diff_psi)\n",
    "\n",
    "            while reduction_likely\n",
    "                # Value of the objective function can most likely be reduced\n",
    "                # Minimize in R^n using 3 points : α_km2, α_km1 and α_k\n",
    "                # New suggestion of the steplength is α_kp1, pk its approximated value\n",
    "                α_kp1, pk = minrn(α_k,ψ_k,α_km1,ψ_km1,α_km2,ψ_km2,α_min,α_max,p_max)\n",
    "\n",
    "                # UPDATE\n",
    "                α_km2 = α_km1\n",
    "                ψ_km2 = ψ_km1\n",
    "                α_km1 = α_k\n",
    "                ψ_km1 = ψ_k\n",
    "                α_k = α_kp1\n",
    "                ψ_k = psi(x,α_k,p,r,c,w,m,l,t,active,inactive)\n",
    "\n",
    "                reduction_likely = check_reduction(α_km1,ψ_km1,α_k,ψ_k,pk,η,diff_psi)\n",
    "            end\n",
    "            # Terminate but choose the best point out of α_km1 and α_k\n",
    "            if (ψ_km1 - pk >= η * diff_psi) && (ψ_k < ψ_km1)\n",
    "                α_km1 = α_k\n",
    "                ψ_km1 = ψ_k\n",
    "            end\n",
    "\n",
    "        else\n",
    "            # Take a pure Goldstein-Armijo step\n",
    "            α_km1 = goldstein_armijo_step(ψ0,dψ0,α_min,τ,p_max,x,α_k,p,r,c,w,m,l,t,active,inactive)\n",
    "        end\n",
    "    end\n",
    "    α = α_km1\n",
    "    return α\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "upper_bound_steplength (generic function with 1 method)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UPBND\n",
    "# Determine the upper bound of the steplength\n",
    "\n",
    "function upper_bound_steplength(\n",
    "        A::Matrix,\n",
    "        cx::Vector,\n",
    "        p::Vector,\n",
    "        inactive::Vector,\n",
    "        t::Int64,\n",
    "        l::Int64,\n",
    "        index_del::Int64)\n",
    "\n",
    "    α_upper = Inf\n",
    "    if norm(inactive, Inf) > 0\n",
    "        for i = 1:l-t\n",
    "            j = inactive[i]\n",
    "            if j != index_del\n",
    "                ∇cjTp = dot(A[j,:],p)\n",
    "                α_j = -cx[j] / ∇cjTp\n",
    "                if cx[j] > 0 && ∇cjTp < 0 && α_j < α_upper\n",
    "                    α_upper = α_j\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    α_upper = min(3., α_upper)\n",
    "    return α_upper\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_steplength (generic function with 1 method)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STPLNG\n",
    "# Update the penalty weights and compute the steplength using the merit function psi\n",
    "# If search direction computed with method of Newton, an undamped step is taken (i.e. α=1)\n",
    "\n",
    "function compute_steplength(\n",
    "    x::Vector,\n",
    "    r::ResidualsEval,\n",
    "    rx::Vector,\n",
    "    J::Matrix,\n",
    "    p::Vector,\n",
    "    c::ConstraintsEval,\n",
    "    cx::Vector,\n",
    "    A::Matrix,\n",
    "    active_constraint::Constraint,\n",
    "    w_old::Vector,\n",
    "    work_set::WorkingSet,\n",
    "    K::Array{Array{Float64,1},1},\n",
    "    dimA::Int64,\n",
    "    m::Int64,\n",
    "    ind_constraint_del::Int64,\n",
    "    previous_α::Float64,\n",
    "    prev_rankJ2::Int64,\n",
    "    rankJ2::Int64,\n",
    "    method_code::Int64)\n",
    "\n",
    "    # Data\n",
    "    error = 0\n",
    "    c1 = 1e-3\n",
    "    rx_sum = dot(rx,rx)\n",
    "    Jp = J*p\n",
    "    Ap = A*p\n",
    "    JpAp = vcat(Jp,Ap)\n",
    "    active_Ap = active_constraint.A * p\n",
    "\n",
    "    if method_code != 2\n",
    "        # Compute penalty weights and derivative of ψ at α = 0\n",
    "        w, dψ0 = penalty_weight_update(w_old, Jp, active_Ap, K, rx, rx_sum, cx, work_set.active, work_set.t, dimA)\n",
    "\n",
    "        #\n",
    "        # Compute ψ(0) = 0.5 * [||r(x)||^2 +    Σ     (w_i*c_i(x)^2)]\n",
    "        #                                   i ∈ active\n",
    "        ψ0 = 0.5 * (dot(rx,rx) + dot(w[work_set.active[1:work_set.t]],cx[work_set.active[1:work_set.t]].^2))\n",
    "        # check is p is a descent direction\n",
    "        if dψ0 >= 0 error = -1 end\n",
    "        # TODO : handle error due to ψ'(0) > 0\n",
    "\n",
    "        # Determine upper bound of the steplength\n",
    "        α_upp = upper_bound_steplength(A, cx, p, work_set.inactive, work_set.t, work_set.l, ind_constraint_del)\n",
    "        α_low = α_upp / 3000.0\n",
    "\n",
    "        # Determine a first guess of the steplength\n",
    "        magfy = (rankJ2 < prev_rankJ2 ? 6.0 : 3.0)\n",
    "        α0 = min(1.0, magfy*previous_α, α_upp)\n",
    "\n",
    "        # Compute the steplength\n",
    "        α = linesearch_constrained(x,α0,p,r,c,rx,cx,JpAp,w,m,work_set.l,work_set.t,work_set.active,work_set.inactive,ψ0,dψ0,α_low,α_upp)\n",
    "\n",
    "    else\n",
    "        w = w_old\n",
    "        α = 1.0\n",
    "    end\n",
    "    # TODO: Computation of predicted linear progress as done in the code\n",
    "    return α, w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "check_termination_criteria (generic function with 1 method)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TERCRI\n",
    "# Check if any of the termination criteria are satisfied\n",
    "# There are convergence criteria and abnormal termination criteria\n",
    "\n",
    "# Convergence criteria\n",
    "# 1) ||active_c(x)|| < ε_c (for constraints in the working set)\n",
    "# 1.5) all inactive constraints must be > 0\n",
    "# 2) ||active_A^T * λ - ∇f(x)|| < sqrt(ε_rel)(1 + ||∇f(x)||)\n",
    "# 3) min λ_i >= ε_rel * max |λ_i|\n",
    "#     i                  i\n",
    "#            >= ε_rel * (1+||r(x)||^2) (if 1 inequality)\n",
    "# 4) ||d1||^2 <= ε_x * ||x||\n",
    "# 5) ||r(x)||^2 <= ε_abs^2\n",
    "# 6) ||x_previous - x|| < ε_x * ||x||\n",
    "# 7) sqrt(ε_rel) / ||p_gn|| > 0.25 (gn for Gauss-Newton)\n",
    "# 8) The last digit in the convergence code has a specific value (TODO : not implemented yet)\n",
    "\n",
    "# Abnormal termination criterias\n",
    "# 9) number of iterations exceeds max_iter\n",
    "# 10) Convergence to a non feasible point\n",
    "# 11) 2nd derivatives not allowed by the user (TOTO (?) : not implemented yet)\n",
    "# 12) Newton step fails\n",
    "# 13) The latest direction is not a descent direction to the merit function (TODO : not implemented yet)\n",
    "\n",
    "# Returns exit_code, an integer containing whose value gives info about termination\n",
    "# 0 if no termination criterion is satisfied\n",
    "# 10000 if criterion 4 satisfied\n",
    "#  2000 if criterion 5 satisfied\n",
    "#   300 if criterion 6 satisfied\n",
    "#    40 if criterion 7 satisfied\n",
    "#    -2 if criterion 9 satisfied\n",
    "#    -5 if criterion 12 satisfied\n",
    "#   -10 if not possible to satisfy the constraints\n",
    "\n",
    "# exit_code != 0 means the termination of the algorithm\n",
    "\n",
    "function check_termination_criteria(\n",
    "    iter::Iteration,\n",
    "    prev_iter::Iteration,\n",
    "    W::WorkingSet,\n",
    "    active_C::Constraint,\n",
    "    x::Vector,\n",
    "    cx::Vector,\n",
    "    rx_sum::Float64,\n",
    "    ∇fx::Vector,\n",
    "    n::Int64,\n",
    "    max_iter::Int64,\n",
    "    nb_iter::Int64,\n",
    "    ε_abs::Float64,\n",
    "    ε_rel::Float64,\n",
    "    ε_x::Float64,\n",
    "    ε_c::Float64\n",
    ")\n",
    "    exit_code = 0\n",
    "    alfnoi = sqrt(ε_rel) / norm(iter.p)\n",
    "\n",
    "    # Preliminary conditions\n",
    "    preliminary_cond = !(iter.restart || (iter.code == -1  && alfnoi <= 0.25))\n",
    "    if preliminary_cond\n",
    "\n",
    "        # Check necessary conditions\n",
    "        grad_res = norm(transpose(active_C.A) * iter.λ - ∇fx)\n",
    "        necessary_crit = (!iter.del) && (norm(active_C.cx) < ε_c) && (grad_res < sqrt(ε_rel)*(1+norm(∇fx)))\n",
    "\n",
    "        if W.l-W.t > 0\n",
    "            inactive_index = W.inactive[1:W.l-W.t]\n",
    "            inactive_cx = cx[inactive_index]\n",
    "            necessary_crit = necessary_crit && (all(>(0), inactive_cx))\n",
    "        end\n",
    "        if W.t > W.q\n",
    "            if W.t == 1\n",
    "                factor = 1 + rx_sum\n",
    "            elseif W.t > 1\n",
    "                factor =  maximum(map(abs,iter.λ))\n",
    "            end\n",
    "\n",
    "            lagrange_mult_pos = [iter.λ[i] for i=W.q+1:W.t if iter.λ[i] > 0]\n",
    "            sigmin = (isempty(lagrange_mult_pos) ? 0 : minimum(lagrange_mult_pos))\n",
    "            necessary_crit = necessary_crit && (sigmin >= ε_rel * factor)\n",
    "\n",
    "        end\n",
    "\n",
    "\n",
    "        if necessary_crit\n",
    "\n",
    "            # Check the sufficient conditions\n",
    "            d1 = @view iter.d_gn[1:iter.dimJ2]\n",
    "            x_diff = norm(prev_iter.x - x)\n",
    "\n",
    "            # Criterion 4\n",
    "            if dot(d1,d1) <= rx_sum * ε_rel^2\n",
    "                exit_code += 10000\n",
    "            end\n",
    "            # Criterion 5\n",
    "            if rx_sum <= ε_abs^2\n",
    "                exit_code += 2000\n",
    "            end\n",
    "            # Criterion 6\n",
    "            if x_diff < ε_x * norm(x)\n",
    "                exit_code += 300\n",
    "            end\n",
    "            # Criterion 7\n",
    "            if alfnoi > 0.25\n",
    "                exit_code += 40\n",
    "            end\n",
    "\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if exit_code == 0\n",
    "\n",
    "        # Check abnormal termination criteria\n",
    "        x_diff = norm(prev_iter.x - iter.x)\n",
    "        Atcx_nrm = norm(transpose(active_C.A) * active_C.cx)\n",
    "        # Criterion 9\n",
    "        if nb_iter >= max_iter\n",
    "            exit_code = -2\n",
    "        # test if impossible to satisfy the constraints\n",
    "        elseif x_diff <= 10.0 * ε_x && Atcx_nrm <= 10.0 * ε_c\n",
    "            exit = -10\n",
    "        end\n",
    "        # TODO : implement critera 10-12\n",
    "    end\n",
    "    return exit_code\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output (generic function with 1 method)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OUTPUT\n",
    "# Print the useful informations at the end of current iteration\n",
    "\n",
    "function output(iter::Iteration, W::WorkingSet, nb_iter::Int64)\n",
    "\n",
    "    s_act = \"(\"\n",
    "    for i=1:W.t\n",
    "        s_act = (i<W.t ? string(s_act,W.active[i],\",\") : string(s_act,W.active[i],\")\"))\n",
    "    end\n",
    "    method = (iter.code > 0 ? \" $(iter.code)\" : \"$(iter.code)\")\n",
    "    if nb_iter == 0\n",
    "        println(\"****************************************\")\n",
    "        println(\"*                                      *\")\n",
    "        println(\"*          ENLSIP-JULIA-0.2.0          *\")\n",
    "        println(\"*                                      *\")\n",
    "        println(\"****************************************\\n\")\n",
    "\n",
    "        println(\"Constraints qualification : $(W.q) equalities, $(W.l) inequalities\\n\")\n",
    "        println(\"iter    objective    method   ||p||   dimA  dimJ2     α       max weight    working set\")\n",
    "        @printf \"   %d  %.8e   %s   %.3e   %d     %d   %.3e   %.4e    %s\\n\"  nb_iter dot(iter.rx,iter.rx) method norm(iter.p) iter.dimA iter.dimJ2 iter.α maximum(iter.w) s_act\n",
    "    elseif nb_iter < 10\n",
    "        @printf \"   %d  %.8e   %s   %.3e   %d     %d   %.3e   %.4e    %s\\n\"  nb_iter dot(iter.rx,iter.rx) method norm(iter.p) iter.dimA iter.dimJ2 iter.α maximum(iter.w) s_act\n",
    "    elseif nb_iter >= 10 && nb_iter < 100\n",
    "        @printf \"  %d  %.8e   %s   %.3e   %d     %d   %.3e   %.4e    %s\\n\"  nb_iter dot(iter.rx,iter.rx) method norm(iter.p) iter.dimA iter.dimJ2 iter.α maximum(iter.w) s_act\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ENLSIP 0.2.0 #####\n",
    "\n",
    "mutable struct ENLSIP\n",
    "    sol::Vector\n",
    "    obj_value::Float64\n",
    "end\n",
    "\n",
    "enlsip_020 = ENLSIP([0.0],0.0)\n",
    "\n",
    "function (enlsip_020::ENLSIP)(x0::Vector,r::ResidualsEval,c::ConstraintsEval,\n",
    "        n::Int64,m::Int64,q::Int64,l::Int64)\n",
    "\n",
    "\n",
    "    ε_float = eps(Float64)\n",
    "    ε_abs = ε_float\n",
    "    ε_rel = sqrt(ε_float)\n",
    "    ε_x = sqrt(ε_float)\n",
    "    ε_c = sqrt(ε_float)\n",
    "    MAX_ITER = 100\n",
    "    nb_iteration = 0\n",
    "\n",
    "    # Vector of penalty constants\n",
    "    K = [zeros(l) for i=1:4]\n",
    "\n",
    "    # Evaluate at starting point\n",
    "    rx,cx = zeros(m), zeros(l)\n",
    "    J,A = zeros(m,n), zeros(l,n)\n",
    "    r.ctrl = 1\n",
    "    c.ctrl = 1\n",
    "    r(x0,rx,J)\n",
    "    c(x0,cx,A)\n",
    "\n",
    "    first_iter = Iteration(x0,zeros(n),rx,cx,l,1.0,zeros(l),zeros(l),0,0,0,0,zeros(n),zeros(n),0.,0.,0.,false,true,false,false,0,1)\n",
    "    working_set = init_working_set(cx, K, first_iter, q, l)\n",
    "    first_iter.t = working_set.t\n",
    "\n",
    "    # Compute jacobians at current point\n",
    "    new_point!(x0, r, rx, c, cx, J, A, n, m, l)\n",
    "\n",
    "    active_C = Constraint(cx[working_set.active[1:working_set.t]], A[working_set.active[1:working_set.t],:])\n",
    "\n",
    "    # Gradient of the objective function\n",
    "    ∇fx = transpose(J) * rx\n",
    "\n",
    "    p_gn = zeros(n)\n",
    "\n",
    "    # Estimation of the Lagrange multipliers\n",
    "    # Computation of the Gauss-Newton search direction\n",
    "    update_working_set!(working_set, rx, A, active_C, ∇fx, J, p_gn, first_iter)\n",
    "    rx_sum = dot(rx,rx)\n",
    "    active_cx_sum = dot(active_C.cx,active_C.cx)\n",
    "    first_iter.t = working_set.t\n",
    "    previous_iter = copy(first_iter)\n",
    "    F_A = qr(transpose(active_C.A), Val(true))\n",
    "    L11, Q1, P1 = Matrix(transpose(F_A.R)), F_A.Q, F_A.P\n",
    "    F_L = qr(L11, Val(true))\n",
    "    R11, Q2, P2 = F_L.R, F_L.Q, F_L.P\n",
    "    J2 = (J*Q1)[:,first_iter.rankA+1:end]\n",
    "    F_J2 = qr(J2, Val(true))\n",
    "    Q3, P3, R22 = F_J2.Q, F_J2.P, F_J2.R\n",
    "    nrm_b1 = norm(first_iter.b_gn[1:first_iter.dimA])\n",
    "    nrm_d1 = norm(first_iter.d_gn[1:first_iter.dimJ2])\n",
    "    nrm_d = norm(first_iter.d_gn)\n",
    "\n",
    "    # Analys of the lastly computed search direction\n",
    "    search_direction_analys!(previous_iter,first_iter,nb_iteration,x0,c,r,rx,cx,active_C.cx,first_iter.λ,rx_sum,active_cx_sum,p_gn,first_iter.d_gn,first_iter.b_gn,nrm_b1,nrm_d1,nrm_d,J,m,n,working_set,first_iter.rankA,first_iter.rankJ2,P1,Q1,L11,P2,Q2,R11,P3,Q3,R22,first_iter.add,first_iter.del)\n",
    "\n",
    "    # Computation of penalty constants and steplentgh\n",
    "    α, w = compute_steplength(x0,r,rx,J,first_iter.p,c,cx,A,active_C,previous_iter.w,working_set, K,first_iter.dimA,m,first_iter.index_del,previous_iter.α,previous_iter.rankJ2,first_iter.rankJ2,first_iter.code)\n",
    "    first_iter.α = α\n",
    "    first_iter.w = w\n",
    "    x = x0 + α*first_iter.p\n",
    "\n",
    "    # Evaluate residuals, constraints and compute jacobians at new point\n",
    "\n",
    "    r.ctrl = 1\n",
    "    c.ctrl = 1\n",
    "    r(x,rx,J)\n",
    "    rx_sum = dot(rx,rx)\n",
    "    c(x,cx,A)\n",
    "    new_point!(x, r, rx, c, cx, J, A, n, m, l)\n",
    "    ∇fx = transpose(J) * rx\n",
    "\n",
    "    # Check for termination criterias at new point\n",
    "    exit_code = check_termination_criteria(first_iter,previous_iter,working_set,active_C,x,cx,rx_sum,∇fx,n,MAX_ITER,nb_iteration,ε_abs,ε_rel,ε_x,ε_c)\n",
    "\n",
    "    # Check for violated constraints and add it to the working set\n",
    "    first_iter.add = evaluate_violated_constraints(cx,working_set)\n",
    "    active_C = Constraint(cx[working_set.active[1:working_set.t]], A[working_set.active[1:working_set.t],:])\n",
    "\n",
    "    previous_iter = first_iter\n",
    "    first_iter.x = x\n",
    "    first_iter.rx = rx\n",
    "    first_iter.cx = cx\n",
    "    output(first_iter, working_set, nb_iteration)\n",
    "    nb_iteration += 1\n",
    "    iter = copy(first_iter)\n",
    "    iter.first = false\n",
    "\n",
    "    # Main loop for next iterations\n",
    "\n",
    "    while exit_code == 0\n",
    "\n",
    "        p_gn = zeros(n)\n",
    "        # Estimation of the Lagrange multipliers\n",
    "        # Computation of the Gauss-Newton search direction\n",
    "        update_working_set!(working_set, rx, A, active_C, ∇fx, J, p_gn, iter)\n",
    "\n",
    "        active_cx_sum = dot(active_C.cx,active_C.cx)\n",
    "        iter.t = working_set.t\n",
    "        F_A = qr(transpose(active_C.A), Val(true))\n",
    "        L11, Q1, P1 = Matrix(transpose(F_A.R)), F_A.Q, F_A.P\n",
    "        F_L = qr(L11, Val(true))\n",
    "        R11, Q2, P2 = F_L.R, F_L.Q, F_L.P\n",
    "        J2 = (J*Q1)[:,iter.rankA+1:end]\n",
    "        F_J2 = qr(J2, Val(true))\n",
    "        Q3, P3, R22 = F_J2.Q, F_J2.P, F_J2.R\n",
    "        nrm_b1 = norm(iter.b_gn[1:iter.dimA])\n",
    "        nrm_d1 = norm(iter.d_gn[1:iter.dimJ2])\n",
    "        nrm_d = norm(iter.d_gn)\n",
    "\n",
    "        # Analys of the lastly computed search direction\n",
    "        search_direction_analys!(previous_iter,iter,nb_iteration,x,c,r,rx,cx,active_C.cx,iter.λ,rx_sum,active_cx_sum,p_gn,iter.d_gn,iter.b_gn,nrm_b1,nrm_d1,nrm_d,J,m,n,working_set,iter.rankA,iter.rankJ2,P1,Q1,L11,P2,Q2,R11,P3,Q3,R22,iter.add,iter.del)\n",
    "\n",
    "        # Computation of penalty constants and steplentgh\n",
    "        α, w = compute_steplength(x,r,rx,J,iter.p,c,cx,A,active_C,previous_iter.w,working_set, K,iter.dimA,m,iter.index_del,previous_iter.α,previous_iter.rankJ2,iter.rankJ2,iter.code)\n",
    "        iter.α = α\n",
    "        iter.w = w\n",
    "        x = x + α * iter.p\n",
    "\n",
    "        # Print some informations about the newly finished iteration\n",
    "\n",
    "        # Evaluate residuals, constraints and compute jacobians at new point\n",
    "        r.ctrl = 1\n",
    "        c.ctrl = 1\n",
    "        r(x,rx,J)\n",
    "        rx_sum = dot(rx,rx)\n",
    "        c(x,cx,A)\n",
    "        new_point!(x, r, rx, c, cx, J, A, n, m, l)\n",
    "        ∇fx = transpose(J) * rx\n",
    "\n",
    "        # Check for termination criterias at new point\n",
    "        exit_code = check_termination_criteria(iter,previous_iter,working_set,active_C,x,cx,rx_sum,∇fx,n,MAX_ITER,nb_iteration,ε_abs,ε_rel,ε_x,ε_c)\n",
    "\n",
    "        # Check for violated constraints and add it to the working set\n",
    "        iter.add = evaluate_violated_constraints(cx,working_set)\n",
    "        active_C = Constraint(cx[working_set.active[1:working_set.t]], A[working_set.active[1:working_set.t],:])\n",
    "\n",
    "        previous_iter = iter\n",
    "        iter.x = x\n",
    "        iter.rx = rx\n",
    "        iter.cx = cx\n",
    "        output(iter,working_set,nb_iteration)\n",
    "        nb_iteration += 1\n",
    "        iter = copy(iter)\n",
    "        iter.del = false\n",
    "        iter.add = false\n",
    "\n",
    "    end\n",
    "    println(\"\\nExit code = $exit_code\")\n",
    "    enlsip_020.sol = iter.x\n",
    "    enlsip_020.obj_value = dot(rx,rx)\n",
    "    @printf \"Objective value = %.9e\\n\" enlsip_020.obj_value\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Tests sur Problèmes jouets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résolution Pb57 de la collection Hock-Schittkowski\n",
    "\n",
    "Classification dans l'ouvrage : SQR-P1-1\n",
    "\n",
    "Number of variables : n = 2\n",
    "\n",
    "Number of constraints : 3 (1 inequality + 2 bounds)\n",
    "\n",
    "## Modèle\n",
    "\n",
    "$\\left\\{  \n",
    "\\begin{array}{llll} \n",
    "\\min f(x) \\\\ \n",
    "\\text{s.c.}\\\\\n",
    "0.49x_2-x_1x_2-0.09 &\\geq 0\\\\\n",
    "x_1\\geq 0.4,\\  x_2 \\geq -4\n",
    "\\end{array} \\right.$\n",
    "\n",
    "où $f : x \\longmapsto \\sum\\limits_{i=1}^{44} f_i(x)^2$\n",
    "\n",
    "avec $f_i(x) = b_i - x_1 - (0.49-x_1)\\exp(-x_2(a_i-8)) \\text{ pour }i=1,\\ldots,44$ \n",
    "\n",
    "Point de départ : $x_0 = (0.42,5)$\n",
    "\n",
    "Solution attendue : $x^* = (0.419952675,1.284845629)$\n",
    "\n",
    "Fonction objectif à la solution : $f(x^*) =0.02845966972$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données d'entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data (generic function with 1 method)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function data()\n",
    "\n",
    "    a = [8.,8.,10.,10.,10.,10.,12.,12.,12.,12.,14.,14.,14.,16.,16.,16.,18.,18.,20.,20.,20.,22.,22.,22., \n",
    "         24.,24.,24.,26.,26.,26.,28.,28.,30.,30.,30.,32.,32.,34.,36.,36.,38.,38.,40.,42.]\n",
    "\n",
    "    b = [.49,.49,.48,.47,.48,.47,.46,.46,.45,.43,.45,.43,.43,.44,.43,.43,.46,.45,.42,.42,.43,.41,\n",
    "         .41,.40,.42,.40,.40,.41,.40,.41,.41,.40,.40,.40,.38,.41,.40,.40,.41,.38,.40,.40,.39,.39]\n",
    "    return a,b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([8.0, 8.0, 10.0, 10.0, 10.0, 10.0, 12.0, 12.0, 12.0, 12.0  …  30.0, 32.0, 32.0, 34.0, 36.0, 36.0, 38.0, 38.0, 40.0, 42.0], [0.49, 0.49, 0.48, 0.47, 0.48, 0.47, 0.46, 0.46, 0.45, 0.43  …  0.38, 0.41, 0.4, 0.4, 0.41, 0.38, 0.4, 0.4, 0.39, 0.39])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résolution avec ENLSIP-0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 2\n",
    "m = 44\n",
    "nb_eq = 0 # nombre de contraintes d'égalité\n",
    "nb_constraints = 3 # nombre de contraintes d'égalité et d'inégalité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résidus et matrice jacobienne associée\n",
    "\n",
    "r_i(x::Vector,t::Float64) = x[1] + (0.49 - x[1]) * exp(-x[2]*(t - 8))\n",
    "res57 = ResidualsEval(0)\n",
    "\n",
    "function (res57::ResidualsEval)(x::Vector,rx::Vector,J::Matrix)\n",
    "    # Evaluate the residuals\n",
    "    if abs(res57.ctrl) == 1\n",
    "        rx[:] = b - (t::Float64 -> r_i(x,t)).(a)\n",
    "\n",
    "    # The jacobian is computed numericaly using forward differences\n",
    "    # ctrl is set to 0\n",
    "    elseif res57.ctrl == 2 res57.ctrl = 0 end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contraintes et matrice jacobienne associée\n",
    "\n",
    "cons57 = ConstraintsEval(0)\n",
    "\n",
    "function (cons57::ConstraintsEval)(x::Vector,cx::Vector,A::Matrix)\n",
    "    # Evaluate the constraints\n",
    "    if abs(cons57.ctrl) == 1\n",
    "        cx[:] = [0.49 * x[2] - x[1] * x[2] - 0.09, x[1] - 0.4, x[2] + 4]\n",
    "    \n",
    "    # The jacobian is computed anaticaly\n",
    "    elseif cons57.ctrl == 2\n",
    "        A[:] = [-x[2] 0.49-x[1];\n",
    "        1.0 0.0;\n",
    "        0.0 1.0]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "*                                      *\n",
      "*          ENLSIP-JULIA-0.2.0          *\n",
      "*                                      *\n",
      "****************************************\n",
      "\n",
      "Constraints qualification : 0 equalities, 3 inequalities\n",
      "\n",
      "iter    objective    method   ||p||   dimA  dimJ2     α       max weight    working set\n",
      "   0  2.84593834e-02   -1   9.233e+03   0     2   4.023e-04   1.0000e-01    (1)\n",
      "   1  2.84595849e-02    1   7.321e-04   1     1   7.560e-01   2.1630e+04    (1)\n",
      "   2  2.84596696e-02   -1   2.021e-04   1     1   1.000e+00   9.4776e+04    (1)\n",
      "   3  2.84596697e-02    1   8.677e-06   1     1   1.000e+00   5.3357e+07    (1)\n",
      "\n",
      "Exit code = 40\n",
      "Objective value = 2.845966972e-02\n"
     ]
    }
   ],
   "source": [
    "x0 = [0.42, 5.0]\n",
    "enlsip_020(x0,res57,cons57,n,m,nb_eq,nb_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution trouvée avec ENLSIP :\n",
      "x_sol = (4.19952672e-01, 1.284845589e+00)\n",
      "f(x_sol) = 2.845966972e-02\n",
      "\n",
      "Valeurs théoriques visées :\n",
      "x_opt = (4.19952675e-01, 1.284845629e+00)\n",
      "f(x_opt) = 2.845966972e-02"
     ]
    }
   ],
   "source": [
    "x1_sol = enlsip_020.sol[1]\n",
    "x2_sol = enlsip_020.sol[2]\n",
    "println(\"Solution trouvée avec ENLSIP :\")\n",
    "@printf \"x_sol = (%.8e, %.9e)\\n\" x1_sol x2_sol\n",
    "@printf \"f(x_sol) = %.9e\\n\" enlsip_020.obj_value  \n",
    "println(\"\\nValeurs théoriques visées :\")\n",
    "@printf \"x_opt = (%.8e, %.9e)\\n\" 0.419952675 1.284845629\n",
    "@printf \"f(x_opt) = %.9e\" 0.02845966972 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résolution avec Ipopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.13.4, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        4\n",
      "Number of nonzeros in Lagrangian Hessian.............:        0\n",
      "\n",
      "Total number of variables............................:        2\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        3\n",
      "        inequality constraints with only lower bounds:        3\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  3.0798602e-02 0.00e+00 7.14e-01   0.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  3.1510710e-02 0.00e+00 5.38e-01  -1.6 3.11e-02    -  9.91e-01 1.00e+00f  1\n",
      "   2  3.2754028e-02 0.00e+00 4.29e-02  -1.4 1.69e-02    -  1.00e+00 1.00e+00h  1\n",
      "   3  3.1373761e-02 0.00e+00 2.26e-02  -2.1 1.43e-02    -  1.00e+00 1.00e+00h  1\n",
      "   4  3.0685211e-02 0.00e+00 8.02e-04  -3.1 1.56e-02    -  1.00e+00 1.00e+00h  1\n",
      "   5  3.0646444e-02 0.00e+00 4.13e-06  -5.1 4.44e-03    -  1.00e+00 1.00e+00h  1\n",
      "   6  3.0646352e-02 0.00e+00 1.68e-06 -10.5 2.25e-04    -  9.99e-01 1.00e+00h  1\n",
      "   7  3.0646352e-02 0.00e+00 1.23e-06 -11.0 2.52e-06    -  1.00e+00 1.00e+00h  1\n",
      "   8  3.0646350e-02 0.00e+00 1.17e-05 -11.0 8.62e-04    -  1.00e+00 1.00e+00h  1\n",
      "   9  3.0644575e-02 0.00e+00 6.15e-03 -11.0 4.73e-01    -  1.00e+00 1.00e+00h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10  3.0622276e-02 0.00e+00 1.42e-02 -11.0 1.05e+00    -  1.00e+00 1.00e+00h  1\n",
      "  11  2.8585892e-02 0.00e+00 2.97e-02  -9.0 9.57e+00    -  1.00e+00 2.27e-01h  1\n",
      "  12  4.6549946e-02 0.00e+00 1.73e+00  -9.6 3.82e-02    -  1.00e+00 7.14e-01h  1\n",
      "  13  2.8580146e-02 0.00e+00 4.17e-03 -10.1 2.75e-02    -  1.08e-02 1.00e+00f  1\n",
      "  14  2.8579928e-02 0.00e+00 2.08e-03 -11.0 6.30e-05    -  1.00e+00 1.00e+00h  1\n",
      "  15  2.8579709e-02 0.00e+00 2.08e-03 -11.0 5.24e-05    -  1.00e+00 1.00e+00h  1\n",
      "  16  2.8579491e-02 0.00e+00 2.08e-03 -11.0 5.24e-05    -  1.00e+00 1.00e+00h  1\n",
      "  17  2.8575479e-02 0.00e+00 4.73e-02 -11.0 4.17e-03    -  1.00e+00 1.00e+00f  1\n",
      "  18  2.8565367e-02 0.00e+00 4.71e-02  -9.1 1.44e-01    -  1.00e+00 1.66e-02h  1\n",
      "  19  2.8565234e-02 0.00e+00 4.71e-02  -7.8 7.89e-02    -  1.00e+00 3.62e-04h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  20  2.8463598e-02 3.07e-05 8.07e-03  -8.0 2.44e-02    -  1.00e+00 1.00e+00h  1\n",
      "  21  2.8462718e-02 1.36e-07 3.16e-03 -10.0 1.62e-03    -  1.00e+00 1.00e+00h  1\n",
      "  22  2.8459569e-02 1.50e-06 2.89e-04  -8.9 5.27e-03    -  1.00e+00 1.00e+00h  1\n",
      "  23  2.8459669e-02 0.00e+00 1.51e-06 -11.0 5.75e-05    -  1.00e+00 1.00e+00h  1\n",
      "  24  2.8459669e-02 0.00e+00 2.95e-09 -11.0 4.62e-08    -  1.00e+00 1.00e+00h  1\n",
      "\n",
      "Number of Iterations....: 24\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   2.8459669065836156e-02    2.8459669065836156e-02\n",
      "Dual infeasibility......:   2.9526275868718699e-09    2.9526275868718699e-09\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   1.0000000015008103e-11    1.0000000015008103e-11\n",
      "Overall NLP error.......:   2.9526275868718699e-09    2.9526275868718699e-09\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 25\n",
      "Number of objective gradient evaluations             = 25\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 25\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 25\n",
      "Number of Lagrangian Hessian evaluations             = 0\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      2.343\n",
      "Total CPU secs in NLP function evaluations           =      0.137\n",
      "\n",
      "EXIT: Optimal Solution Found.\n"
     ]
    }
   ],
   "source": [
    "model = Model(with_optimizer(Ipopt.Optimizer))\n",
    "@variable(model, x1, start = 0.42)\n",
    "@variable(model, x2, start = 5.)\n",
    "\n",
    "function f_i(x1, x2, t::Float64)\n",
    "    return x1 + (0.49 - x1) * exp(-x2*(t - 8))\n",
    "end\n",
    "\n",
    "function f(x1, x2)\n",
    "    y = b - (t::Float64 -> f_i(x1,x2,t)).(a)\n",
    "    return dot(y,y) \n",
    "end\n",
    "\n",
    "JuMP.register(model, :f, 2, f, autodiff=true)\n",
    "\n",
    "@NLconstraint(model, c1, 0.49*x2 - x1*x2 - 0.09 >= 0)\n",
    "@constraint(model, x1 >= 0.4)\n",
    "@constraint(model, x2 >= -4)\n",
    "\n",
    "@NLobjective(model, Min, f(x1,x2))\n",
    "\n",
    "JuMP.optimize!(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution ENLSIP-Julia :\n",
      "x_sol = (4.19952672e-01, 1.284845589e+00)\n",
      "f(x_sol) = 2.845966972e-02\n",
      "\n",
      "Solution Ipopt :\n",
      "x_opt = (4.19952650e-01, 1.284845043e+00)\n",
      "f(x_opt) = 2.845966907e-02 "
     ]
    }
   ],
   "source": [
    "println(\"Solution ENLSIP-Julia :\")\n",
    "@printf \"x_sol = (%.8e, %.9e)\\n\" x1_sol x2_sol\n",
    "@printf \"f(x_sol) = %.9e\\n\" enlsip_020.obj_value \n",
    "println(\"\\nSolution Ipopt :\")\n",
    "@printf \"x_opt = (%.8e, %.9e)\\n\" JuMP.value(x1) JuMP.value(x2)\n",
    "@printf \"f(x_opt) = %.9e \" 0.028459669065836156"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résolution Pb65 de la collection Hock-Schittkowski\n",
    "\n",
    "Classification dans l'ouvrage : QQR-P1-3\n",
    "\n",
    "Number of variables : n = 3\n",
    "\n",
    "Number of constraints : 7 (1 inequality + 6 bounds)\n",
    "\n",
    "## Modèle\n",
    "\n",
    "$\\left\\{  \n",
    "\\begin{array}{lllll} \n",
    "\\min f(x) \\\\ \n",
    "\\text{s.c.}\\\\\n",
    " 48-x_1^2-x_2^2-x_3^2\\geq 0\\\\\n",
    "-4.5\\leq x_i\\leq 4.5,\\text{ pour } i=1,2\\\\\n",
    "-5 \\leq x_3 \\leq 5\n",
    "\\end{array} \\right.$\n",
    "\n",
    "où $f : x \\longmapsto (x_1-x_2)^2 + \\dfrac{(x_1+x_2-10)^2}{9}+(x_3-5)^2=||r(x)||^2$\n",
    "\n",
    "avec $r : x\\longmapsto  (x_1-x_2,\\dfrac{x_1-x_2-10}{3},x_3-5)$\n",
    "\n",
    "Point de départ : $x_0 = (-5,5,0)$ (non réalisable)\n",
    "\n",
    "Fonction objectif en $x_0$ : $\\dfrac{1225}{9}$\n",
    "\n",
    "Solution attendue : $x^* = (3.650461821,3.65046168,4.6204170507)$\n",
    "\n",
    "Fonction objectif à la solution : $f(x^*) = 0.935288567$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3\n",
    "m = 3\n",
    "nb_eq = 0\n",
    "nb_constraints = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "res65 = ResidualsEval(0)\n",
    "\n",
    "function (res65::ResidualsEval)(x::Vector, rx::Vector, J::Matrix)\n",
    "\n",
    "    # Evaluate the residuals\n",
    "    if abs(res65.ctrl) == 1\n",
    "        rx[:] = [x[1] - x[2]; (x[1]+x[2]-10.0) / 3.0; x[3]-5.0]\n",
    "\n",
    "    # The jacobian is computed analytically\n",
    "    elseif res65.ctrl == 2\n",
    "        J[:] = [1. -1. 0;\n",
    "                1/3 1/3 0.;\n",
    "                0. 0. 1.]\n",
    "    end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons65 = ConstraintsEval(0)\n",
    "\n",
    "function (cons65::ConstraintsEval)(x::Vector, cx::Vector, A::Matrix)\n",
    "\n",
    "    # Evaluate the constraints\n",
    "    if abs(cons65.ctrl) == 1\n",
    "        cx[:] = [48.0 - x[1]^2-x[2]^2-x[3]^2;\n",
    "                 x[1]+4.5;\n",
    "                 x[2]+4.5;\n",
    "                 x[3]+5.0;\n",
    "                 -x[1]+4.5;\n",
    "                 -x[2]+4.5;\n",
    "                 -x[3]+5.0]\n",
    "    # The jacobian is computed numerically if ctrl is set to 0 on return\n",
    "    elseif cons65.ctrl == 2\n",
    "        cons65.ctrl = 0\n",
    "    end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "*                                      *\n",
      "*          ENLSIP-JULIA-0.2.0          *\n",
      "*                                      *\n",
      "****************************************\n",
      "\n",
      "Constraints qualification : 0 equalities, 7 inequalities\n",
      "\n",
      "iter    objective    method   ||p||   dimA  dimJ2     α       max weight    working set\n",
      "   0  1.15890666e+02   -1   5.002e+00   2     1   4.811e-01   1.0000e-01    (1,2,6)\n",
      "   1  7.83190970e+01    1   6.835e+00   2     1   4.297e-01   1.0000e-01    (1,6,7)\n",
      "   2  4.66500919e+00    1   8.193e+00   2     1   7.579e-01   1.0000e-01    (1,6,7)\n",
      "   3  9.54796076e-01    1   1.439e+00   2     1   1.000e+00   1.0000e-01    (1,7)\n",
      "   4  9.37670534e-01    1   4.655e-01   1     2   1.000e+00   1.0000e-01    (1)\n",
      "   5  9.53201789e-01    1   6.668e-02   1     2   1.000e+00   7.0704e-01    (1)\n",
      "   6  9.53524277e-01    1   7.921e-03   1     2   1.000e+00   3.4804e+01    (1)\n",
      "   7  9.53528784e-01    1   9.971e-04   1     2   1.000e+00   2.4542e+03    (1)\n",
      "   8  9.53528856e-01    1   1.252e-04   1     2   1.000e+00   1.5489e+05    (1)\n",
      "   9  9.53528857e-01    1   1.573e-05   1     2   1.000e+00   9.8266e+06    (1)\n",
      "  10  9.53528857e-01    1   1.977e-06   1     2   1.000e+00   6.2155e+08    (1)\n",
      "\n",
      "Exit code = 40\n",
      "Objective value = 9.535288568e-01\n"
     ]
    }
   ],
   "source": [
    "x0 = [-5.0;5.0;0.0]\n",
    "enlsip_020(x0,res65,cons65,n,m,nb_eq,nb_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution trouvée avec ENLSIP-Julia :\n",
      "x_jul = (3.650461829e+00, 3.650461829e+00, 4.620417391e+00)\n",
      "f(x_jul) = 9.535288568e-01\n",
      "\n",
      "Solution trouvée avec ENLSIP-Fortran :\n",
      "x_for = (3.6504617e+00, 3.6504617e+00, 4.6204176e+00)\n",
      "f(x_for) = 9.53529e-01\n",
      "\n",
      "Valeurs théoriques visées :\n",
      "x_opt = (3.650461821e+00, 3.650461680e+00, 4.620417051e+00)\n",
      "f(x_opt) = 9.535288567e-01"
     ]
    }
   ],
   "source": [
    "x1_sol = enlsip_020.sol[1]\n",
    "x2_sol = enlsip_020.sol[2]\n",
    "x3_sol = enlsip_020.sol[3]\n",
    "\n",
    "println(\"Solution trouvée avec ENLSIP-Julia :\")\n",
    "@printf \"x_jul = (%.9e, %.9e, %.9e)\\n\" x1_sol x2_sol x3_sol\n",
    "@printf \"f(x_jul) = %.9e\\n\\n\" enlsip_020.obj_value  \n",
    "\n",
    "println(\"Solution trouvée avec ENLSIP-Fortran :\")\n",
    "@printf \"x_for = (%.7e, %.7e, %.7e)\\n\"  3.6504617  3.6504617  4.6204176\n",
    "@printf \"f(x_for) = %.5e\\n\"  0.953529\n",
    "\n",
    "println(\"\\nValeurs théoriques visées :\")\n",
    "@printf \"x_opt = (%.9e, %.9e, %.9e)\\n\" 3.650461821 3.65046168 4.6204170507\n",
    "@printf \"f(x_opt) = %.9e\" 0.9535288567"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résolution avec Ipopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.13.4, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        9\n",
      "Number of nonzeros in Lagrangian Hessian.............:        0\n",
      "\n",
      "Total number of variables............................:        3\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        7\n",
      "        inequality constraints with only lower bounds:        4\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        3\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  1.3611111e+02 2.00e+00 3.33e+00   0.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  1.3111783e+02 2.10e+00 4.70e+00  -5.6 7.14e+00    -  2.34e-01 6.85e-02f  1\n",
      "   2  1.9503672e+02 1.98e+01 7.09e+01   2.3 1.21e+04    -  5.47e-05 1.01e-03f  1\n",
      "   3  8.6817662e+01 0.00e+00 3.80e+01   0.4 4.02e+01    -  2.63e-01 1.00e+00f  1\n",
      "   4  1.7072377e+01 0.00e+00 1.15e+01  -0.3 2.56e+01    -  3.68e-01 1.00e+00f  1\n",
      "   5  4.8737905e+00 0.00e+00 1.17e+00   0.0 4.66e+01    -  9.94e-01 1.00e+00f  1\n",
      "   6  1.1059971e+00 0.00e+00 1.98e-01  -1.9 2.62e+01    -  8.70e-01 1.00e+00f  1\n",
      "   7  9.7438984e-01 3.23e-02 4.05e-02  -0.7 5.16e+00    -  1.00e+00 9.89e-01h  1\n",
      "   8  9.6159221e-01 0.00e+00 1.16e-01  -2.6 5.54e-02    -  9.99e-01 1.00e+00h  1\n",
      "   9  9.5316864e-01 4.50e-03 2.06e-03  -3.8 5.69e-02    -  9.99e-01 1.00e+00h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10  9.5353095e-01 0.00e+00 1.46e-04  -5.5 2.55e-03    -  1.00e+00 1.00e+00h  1\n",
      "  11  9.5352886e-01 0.00e+00 1.03e-07 -11.0 3.95e-05    -  1.00e+00 1.00e+00h  1\n",
      "  12  9.5352886e-01 0.00e+00 1.30e-09 -11.0 9.18e-08    -  1.00e+00 1.00e+00h  1\n",
      "\n",
      "Number of Iterations....: 12\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   9.5352885599324944e-01    9.5352885599324944e-01\n",
      "Dual infeasibility......:   1.3043728118973420e-09    1.3043728118973420e-09\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   1.0000553687781520e-11    1.0000553687781520e-11\n",
      "Overall NLP error.......:   1.3043728118973420e-09    1.3043728118973420e-09\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 13\n",
      "Number of objective gradient evaluations             = 13\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 13\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 13\n",
      "Number of Lagrangian Hessian evaluations             = 0\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.588\n",
      "Total CPU secs in NLP function evaluations           =      0.000\n",
      "\n",
      "EXIT: Optimal Solution Found.\n"
     ]
    }
   ],
   "source": [
    "model = Model(with_optimizer(Ipopt.Optimizer))\n",
    "\n",
    "@variable(model, x1, start = -5.0)\n",
    "@variable(model, x2, start = 5.0)\n",
    "@variable(model, x3, start = 0.0)\n",
    "\n",
    "f(x1,x2,x3) = (x1 - x2)^2 + (x1+x2-10.0)^2 / 9.0 + (x3-5.0)^2\n",
    "JuMP.register(model, :f, 3, f, autodiff=true)\n",
    "\n",
    "@NLconstraint(model, c1, 48.0 - x1^2 - x2^2 - x3^2 >= 0)\n",
    "@constraint(model, x1 >= -4.5)\n",
    "@constraint(model, -x1 <= 4.5)\n",
    "@constraint(model, x2 >= -4.5)\n",
    "@constraint(model, x2 <= 4.5)\n",
    "@constraint(model, x3 >= -5.0)\n",
    "@constraint(model, x3 <= 5.0)\n",
    "\n",
    "@NLobjective(model, Min, f(x1,x2,x3))\n",
    "\n",
    "JuMP.optimize!(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution trouvée avec ENLSIP :\n",
      "x_enlsip = (3.650461829e+00, 3.650461829e+00, 4.620417391e+00)\n",
      "f(x_enlsip) = 9.535288568e-01\n",
      "\n",
      "Solution trouvée avec Ipopt :\n",
      "x_ipopt = (3.650461727e+00, 3.650461725e+00, 4.620417555e+00)\n",
      "f(x_ipopt) = 9.535288560e-01\n"
     ]
    }
   ],
   "source": [
    "println(\"Solution trouvée avec ENLSIP :\")\n",
    "@printf \"x_enlsip = (%.9e, %.9e, %.9e)\\n\" x1_sol x2_sol x3_sol\n",
    "@printf \"f(x_enlsip) = %.9e\\n\\n\" enlsip_020.obj_value \n",
    "\n",
    "\n",
    "println(\"Solution trouvée avec Ipopt :\")\n",
    "@printf \"x_ipopt = (%.9e, %.9e, %.9e)\\n\" JuMP.value(x1) JuMP.value(x2) JuMP.value(x3)\n",
    "@printf \"f(x_ipopt) = %.9e\\n\" 0.95352885599324944"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
